---
title: "Tree Phenology Assignment"
author: "Olamide Akinlade"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_float: true
    toc-title: "Contents"
    toc-depth: 5
    toc-location: left
    number_sections: true
    fig_caption: true
    code-tools: true
    code-fold: true
    code-summary: 'Show code'
    code-link: true
    code_highlight: tango
    code_download: true
    theme: sandstone
    highlight: tango
    smooth-scroll: true
editor: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



------------------------------------------------------------------------

# Chapter 3: Tree Phenology Analysis

## 1.1 Tree Dormancy

Winter dormancy may be defined as a trade-off between the length of the
growing season and the protection against winter damage. To enter
dormancy, vegetative growth is stopped in the late summer or early
autumn and the shoots are converted into buds, where the shoot apical
meristems are protected by tightly closed and hardened bud scales.

### 1.1.1 Dormancy Phases

1.  Dormancy Establishment
2.  Endodormancy 1: Ecodormancy
3.  Growth resumption

### 1.1.2 Physological processes that regulate dormancy

a.  Transport
b.  Photohormones
c.  Genetics
d.  Carbohydrates dynamics

## ***Exercises on Tree Dormancy***

1.  Put yourself in the place of a breeder who wants to calculate the
    temperature requirements of a newly released cultivar. Which method
    will you use to calculate the chilling and forcing periods? Please
    justify your answer

Statistical method is recommended to calculate the temperature
requirements (chilling and forcing periods) of a newly released
cultivar. This involves using partial least square regression analysis
for daily temperatures over a continuous period.

2.  Which are the advantages (2) of the BBCH scale compared with earlier
    scales?

Two advantages of the BBCH scale over traditional scale include: a. It
was developed in a general frame for all the species b. It covers the
whole development of a plant.

3.  Classify the following phenological stages of sweet cherry according
    to the BBCH scale:

Phenological stages of cherry + Image 1: 51

-   Image 2: 63

-   Image 3: 87

![Stages of
Cherry](\Users\Home\Downloads\photo_5834526249584805567_y.jpg)

------------------------------------------------------------------------

# Chapter 4: Climate Change and impact projection

# 1.1 Drivers of Climate change include:

-   Sun: Warms the earth through radiation. It is an important driver of
    climate change on geological timescales, but not of recent climate
    change.
-   Aerosols: They are largely dusts. Suspensions of liquid, solid, or
    mixed particles with highly variable chemical composition and size
    distribution.
-   Clouds: Can have both cooling and warming effect.
-   Ozone: Surface (tropospheric) ozone: constituent of smog, health
    hazard (bad ozone). Greenhouse gas: presence in the stratosphere has
    a warming effect. Destroyed by chlorofluorocarbons (CFCs).
-   Surface albedo: Reflection of radiation by the land surface. Light
    surfaces (e.g. ice, snow) reflect almost all radiation, dark
    surfaces (ocean, dark soil, forest) very little.
-   Greenhouse gases: Atmospheric gases that trap heat on Earth.
    Greenhouse effects warms the planet.
-   Long-term drivers:

## ***Exercises on Climate Change***

1.  List the main drivers of climate change at the decade to century
    scale, and briefly explain the mechanism through which the currently
    most important driver affects our climate.

-   Sun
-   Aerosols
-   Clouds
-   Ozone
-   Surface albedo
-   Greenhouse gases
-   Long-term drivers

Most important: **GHGs** **Greenhouse effect** + Raises Earth’s mean
temperature: +14°C instead of -18°C without GHGs! + Major GHGs: water
vapor, CO2 (carbon dioxide), CH4 (methane), N2O (nitrous oxide)

1.  Explain briefly what is special about temperature dynamics of recent
    decades, and why we have good reasons to be concerned.

Since 1901 strong warming (almost) everywhere on Earth.Up to 8°C warmer
than the 2003-2018 average. Precipitation anomalies (relative to median
prec.) for Cologne/Bonn weather station. Some years with dry
springs/summer.

1.  What does the abbreviation ‘RCP’ stand for, how are RCPs defined,
    and what is their role in projecting future climates? Representative
    Concentration Pathways (RCPs). It is a new greenhouse forcing
    scenarios in the IPCC‘s5th Assessment Report. From RCP to inputs for
    climate change impact models.

Roles of RCP:

1.  Briefly describe the 4 climate impact projection methods described
    in the fourth video.

-   Statistical models
-   Species distribution modeling
-   Process-based models
-   Climate analogue analysis

------------------------------------------------------------------------

# Chapter 5: Winter Chill Projections

## ***Exercises on past chill projections***

1.  Sketch out three data access and processing challenges that had to
    be overcome in order to produce chill projections with
    state-of-the-art methodology.

-   Accessing Climate Data for Specific Locations: Previous climate
    datasets like AFRICLIM and ClimateWizard only provided large-scale
    data. To get weather data for specific locations without downloading
    too much extra information, an API was created to quickly access
    data for single sites
-   Converting Daily to Hourly Temperature Data: Chill models need
    hourly temperature data, but many databases only give daily
    averages. Early methods for converting daily to hourly data weren’t
    very good, especially in areas with unique temperatures. Improved
    algorithms were developed to estimate hourly temperatures more
    accurately from daily data
-   Handling Large Volumes of Climate Model Outputs: Studying different
    climate futures involves dealing with a lot of data from many
    climate models, which can be hard to manage. To handle this large
    amount of data effectively, workflows were streamlined and selective
    processing techniques were used

2.  Outline, in your understanding, the basic steps that are necessary
    to make such projections.

-   Data Collection and Calibration: collect historical weather data and
    use it to calibrate a weather generator for realistic temperature
    simulations
-   Model Selection and Scenario Setup: choose relevant climate models
    and emission scenarios to explore various future climates
-   Generate Temperature Projections: downscale climate data, converting
    it to daily or hourly temperatures as needed for chill calculations
-   Chill Calculation: apply chill models to estimate chill accumulation
    across different climate scenarios
-   Analysis and Visualization: compare chill projections across models
    and scenarios and visualize the findings
-   Interpretation: validate projections with observed data where
    possible and assess agricultural impacts and adaptation needs

------------------------------------------------------------------------

# Chapter 6: Manual Chill Analysis



```{r}
library(chillR)
library(dplyr)
library(kableExtra)

Winters_hours_gaps[1:10,]
```



## ***Computing Chilling Hours from Hourly Temperature data***

1.  Write a basic function that calculates warm hours (\>25°C)



```{r}
hourtemps <- Winters_hours_gaps[,c("Year",
                                   "Month",
                                   "Day",
                                   "Hour",
                                   "Temp")]
hourtemps[, "Chilling_Hour"] <- hourtemps$Temp >= 0 & hourtemps$Temp <= 7.2
```



#calculate warm hours



```{r}
WH<-function(hourtemps)
{
  hourtemps[, "Warm_Hour"] <-
    hourtemps$Temp >= 25 
  
  return(hourtemps)
}
```



2.  Apply this function to the Winters_hours_gaps dataset



```{r}
WH(hourtemps)[1:50, ]

sum(hourtemps$Warm_Hour)
```



3.  Extend this function, so that it can take start and end dates as
    inputs and sums up warm hours between these dates



```{r}
sum_WH <- function(hourtemps, 
                   startYEARMODAHO,
                   endYEARMODAHO)
  
{hourtemps[,"Warm_Hour"] <- hourtemps$Temp > 25

startYear <- as.numeric(substr(startYEARMODAHO, 1, 4))
startMonth <- as.numeric(substr(startYEARMODAHO, 5, 6))
startDay <- as.numeric(substr(startYEARMODAHO, 7, 8))
startHour <- as.numeric(substr(startYEARMODAHO, 9, 10))

endYear <- as.numeric(substr(endYEARMODAHO, 1, 4))
endMonth <- as.numeric(substr(endYEARMODAHO, 5, 6))
endDay <- as.numeric(substr(endYEARMODAHO, 7, 8))
endHour <- as.numeric(substr(endYEARMODAHO, 9, 10))


Start_Date <- which(hourtemps$Year == startYear &
                    hourtemps$Month == startMonth &
                    hourtemps$Day == startDay &
                    hourtemps$Hour == startHour)

End_Date <- which(hourtemps$Year == endYear &
                  hourtemps$Month == endMonth &
                  hourtemps$Day == endDay &
                  hourtemps$Hour == endHour)

WHs <- sum(hourtemps$Warm_Hour[Start_Date:End_Date])
return(WHs)
}
```



#Example



```{r}
sum_WH(Winters_hours_gaps, startYEARMODAHO = 2008070100, 
                           endYEARMODAHO = 2008073123)
```



------------------------------------------------------------------------

# Chapter 7: Winter Chill Projections

## ***Exercises Chill Models***

1.  Run the chilling() function on the Winters_hours_gap dataset
    #chilling function



```{r}
july <- chilling(make_JDay(Winters_hours_gaps),
                   Start_JDay = 183, 
                   End_JDay = 213)
```



1.  Create your own temperature-weighting chill model using the
    step_model() function #step model



```{r}
df <- data.frame(
  lower = c(-1000, 0,  2, 4, 6, 8,   10),  
  upper = c(    0, 1, 3, 5, 7, 9, 1000), 
  weight = c(   0, 1,  2,  3,  2,  1,    0))

kable(df) %>%
  kable_styling("striped", position = "left", font_size = 12)

custom <- function(x) step_model(x, df)

custom(Winters_hours_gaps$Temp)[1:100]
```



1.  Run this model on the Winters_hours_gaps dataset using the
    tempResponse() function.



```{r}
output <- tempResponse(make_JDay(Winters_hours_gaps),
                       Start_JDay = 183,
                       End_JDay = 213,
                       models = list(Chill_Portions = Dynamic_Model, 
                                     GDH = GDH))

kable(output) %>%
  kable_styling("striped", 
                position = "left",
                font_size = 12)
```



------------------------------------------------------------------------

# Chapter 8: Making Hourly Temperatures

## ***Exercises on hourly*** 

1.  Choose a location of interest, find out its latitude and produce
    plots of daily sunrise, sunset and daylength



```{r}
require(chillR)
library(ggplot2)
library(tidyr)
```



# sunset time and daylength at Rochester (Latitude: 43.15°N) over the
course of the year.



```{r}
Days <- daylength(latitude = 43,
                  JDay = 1:365)
Days_df <-
  data.frame(
    JDay = 1:365,
    Sunrise = Days$Sunrise,
    Sunset = Days$Sunset,
    Daylength = Days$Daylength
  )

Days_df <- pivot_longer(Days_df, cols=c(Sunrise:Daylength))


ggplot(Days_df, aes(JDay, value)) +
  geom_line(lwd = 1.5) +
  facet_grid(cols = vars(name)) +
  ylab("Time of Day / Daylength (Hours)") +
  theme_bw(base_size = 20)
```



1.  Produce an hourly dataset, based on idealized daily curves, for the
    KA_weather dataset (included in chillR)



```{r}
stack_hourly_temps(KA_weather, latitude = 43) [[1]][1:20,]
```



1.  Produce empirical temperature curve parameters for the Winters_hours_gaps dataset, and use them to predict hourly values from daily temperatures (this is very similar to the example above,but please make sure you understand what’s going on).



```{r}
empi_curve <- Empirical_daily_temperature_curve(Winters_hours_gaps)
```

```{r}
Winters_daily <- make_all_day_table(Winters_hours_gaps, input_timestep = "hour")
```



------------------------------------------------------------------------

# Chapter 9: Some Useful tools in R

## ***Exercises on useful R tools*** 

1.  Based on the Winters_hours_gaps dataset, use magrittr pipes and
    functions of the tidyverse to accomplish the following:

-   Convert the dataset into a tibble
-   Select only the top 10 rows of the dataset



```{r}
require(chillR)
library(tidyverse)

WHG <- as_tibble(Winters_hours_gaps[1:10, ])
WHG
```



-   Convert the tibble to a long format, with separate rows for
    Temp_gaps and Temp



```{r}
WHGlong <- WHG %>% pivot_longer(cols = Temp_gaps:Temp)
WHGlong
```



-   Use ggplot2 to plot Temp_gaps and Temp as facets (point or line
    plot)


```{r}
ggplot(WHGlong, aes(Hour, value)) +
  geom_point(aes(colour=0.2), size=12) +
  geom_point(shape = 1, size = 12,colour = "black") +
  ylab("Temperature (°C)") +
  theme_bw(base_size = 12)
```


    
-   Convert the dataset back to the wide format



```{r}
WHGwide <- WHGlong %>% pivot_wider(names_from = name)
WHGwide
```



-   Select only the following columns: Year, Month, Day and Temp



```{r}
WHG %>% select(c(Year, Month, Day, Temp))
```



-   Sort the dataset by the Temp column, in descending order



```{r}
WHG %>% arrange(desc(Temp))
```



1.  For the Winter_hours_gaps dataset, write a for loop to convert all
    temperatures (Temp column) to degrees Fahrenheit


```{r}
Temp <- Winters_hours_gaps$Temp[183:213] # JDay for July

for (i in Temp)
{
  Fahrenheit <- i * 1.8 + 32 
  print(Fahrenheit) 
}
```


    

2.  Execute the same operation with a function from the apply family



```{r}
x <- Winters_hours_gaps$Temp[183:213]

fahrenheit <- function(x)
  x * 1.8 + 32

sapply(x, fahrenheit)
```




3.  Now use the tidyverse function mutate to achieve the same outcome


```{r}
WHG_F <- WHG %>% mutate(Temp_F = Temp * 1.8 + 32)
WHG_F
```




------------------------------------------------------------------------

# Chapter 10: Getting temperature data

## ***Exercises on getting temperature data*** 

1.  Choose a location of interest and find the 25 closest weather
    stations using the handle_gsod function



```{r}
library(chillR)
station_list_Rochester <-handle_gsod(action="list_stations",
                          location=c(-77.60, 43.15),
                          time_interval=c(1990,2020))
library(magrittr)
require(kableExtra)

kable(station_list_Rochester) %>%
  kable_styling("striped", position = "left", font_size = 8)

station_list_Rochester

```



1.  Download weather data for the most promising station on the list



```{r}
weather <- handle_gsod(action = "download_weather",
                       location = station_list_Rochester$chillR_code[1],
                       time_interval = c(1990, 2020))

weather[[1]][1:20,]
```



1.  Convert the weather data into chillR format



```{r}
cleaned_weather <- handle_gsod(weather)

cleaned_weather[[1]][1:20,]

dir.create("data_New_York")
write.csv(station_list_Rochester,
          "data_New_York/station_list_Rochester.csv",
          row.names = FALSE)
write.csv(weather[[1]],
          "data_New_York/Rochester_weather.csv",
          row.names = FALSE)
write.csv(cleaned_weather[[1]],
          "data_New_York/Rochester_chillR_weather.csv",
          row.names = FALSE)
```



------------------------------------------------------------------------

# Chapter 11: Getting temperature data

## ***Exercises on getting temperature data*** 

1.  Use chillR functions to find out how many gaps you have in this
    dataset (even if you have none, please still follow all further
    steps)



```{r}
Rochester <- read.csv("data_New_York/Rochester_chillR_weather.csv")

Rochester_QC <- fix_weather(Rochester)$QC
```



2.  Create a list of the 25 closest weather stations using the
    handle_gsod function



```{r}

station_list <- handle_gsod(action="list_stations",
                            location=c(-77.60, 43.15),
                              time_interval=c(1990,2020))
 
station_list

print(station_list, n = 26)
```



3.  Identify suitable weather stations for patching gaps

#download stations number 4, 5, and 10 these will be used to patch
the gaps

4.  Download weather data for promising stations, convert them to chillR
    format and compile them in a list



```{r}
patch_weather<-
  handle_gsod(action = "download_weather",
              location = as.character(station_list$chillR_code[c(4,5,10)]),
              time_interval = c(1990,2020)) %>%
  handle_gsod()
```



5.  Use the patch_daily_temperatures function to fill gaps



```{r}
patched <- patch_daily_temperatures(weather = Rochester,
                                    patch_weather = patch_weather)


patched$statistics[[1]]

patched$statistics[[2]]

patched$statistics[[3]]
```



#set minimum quality criteria



```{r}
patched <- patch_daily_temperatures(weather = Rochester,
                                    patch_weather = patch_weather,
                                    max_mean_bias = 1,
                                    max_stdev_bias = 2)

patched$statistics[[1]]

patched$statistics[[2]]

patched$statistics[[3]]
```



6.  Investigate the results - have all gaps been filled?



```{r}
post_patch_stats <- fix_weather(patched)$QC

post_patch_stats
```



7.  If necessary, repeat until you have a dataset you can work with in
    further analyses



```{r}
Rochester_weather<-fix_weather(patched)

patched_monthly <- patch_daily_temps(weather = Rochester,
                                     patch_weather = patch_weather,
                                     max_mean_bias = 1,
                                     max_stdev_bias = 2,
                                     time_interval = "month")
```



#saving the data for later



```{r}
monthly_bias_fixed <- fix_weather(patched_monthly)

write.csv(monthly_bias_fixed$weather,
          "data_New_York/Rochester_weather.csv")
```



------------------------------------------------------------------------

# Chapter 12: Generating temperature scenarios

## ***Exercises on getting temperature data*** 

1.  For the location you chose for your earlier analyses, use chillR’s
    weather generator to produce 100 years of synthetic temperature
    data.


```{r, eval = FALSE}

library(chillR)
library(tidyverse) 

Rochester <- read.csv('data_New_York/Rochester_weather.csv')

Temp <- Rochester %>%
  temperature_generation(years = c(1998,2009),
                         sim_years = c(2001,2100))

library(dplyr)
library(magrittr)

Temperatures <- Rochester %>% 
  select(Year, Month, Day, Tmin, Tmax) %>% 
  filter(Year %in% 1998:2009) %>%
  cbind(Data_source = "observed") %>%
  rbind(
    Temp[[1]] %>% select(c(Year,
                           Month,
                           Day,
                           Tmin,
                           Tmax)) %>%
      cbind(Data_source = "simulated")
    ) %>%
  mutate(Date = as.Date(ISOdate(2000,
                                Month,
                                Day)))

ggplot(data = Temperatures,
       aes(Date,
           Tmin)) +
  geom_smooth(aes(colour = factor(Year))) +
  facet_wrap(vars(Data_source)) +
  theme_bw(base_size = 20) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b")

ggplot(data = Temperatures,
       aes(Date,
           Tmax)) +
  geom_smooth(aes(colour = factor(Year))) +
  facet_wrap(vars(Data_source)) +
  theme_bw(base_size = 20) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b")
```



2.  Calculate winter chill (in Chill Portions) for your synthetic
    weather, and illustrate your results as histograms and cumulative
    distributions.


```{r, eval = FALSE}

library(chillR)
library(tidyverse) 

Rochester <- read.csv('data_New_York/Rochester_weather.csv')

Temp <- Rochester %>%
  temperature_generation(years = c(1998,2009),
                         sim_years = c(2001,2100))

library(dplyr)
library(magrittr)

Temperatures <- Rochester %>% 
  select(Year, Month, Day, Tmin, Tmax) %>% 
  filter(Year %in% 1998:2009) %>%
  cbind(Data_source = "observed") %>%
  rbind(
    Temp[[1]] %>% select(c(Year,
                           Month,
                           Day,
                           Tmin,
                           Tmax)) %>%
      cbind(Data_source = "simulated")
    ) %>%
  mutate(Date = as.Date(ISOdate(2000,
                                Month,
                                Day)))

chill_observed <- Temperatures %>%
  filter(Data_source == "observed") %>%
  stack_hourly_temps(latitude = 43.15) %>%
  chilling(Start_JDay = 305,
           End_JDay = 59)
  
chill_simulated <- Temperatures %>%
  filter(Data_source == "simulated") %>%
  stack_hourly_temps(latitude = 43.15) %>%
  chilling(Start_JDay = 305,
           End_JDay = 59)
  
chill_comparison <-
  cbind(chill_observed,
        Data_source = "observed") %>%
  rbind(cbind(chill_simulated,
              Data_source = "simulated"))
  
chill_comparison_full_seasons <- 
  chill_comparison %>%
  filter(Perc_complete == 100)

ggplot(chill_comparison_full_seasons,
       aes(x = Chill_portions)) + 
  geom_histogram(binwidth = 1,
                 aes(fill = factor(Data_source))) +
  theme_bw(base_size = 20) +
  labs(fill = "Data source") +
  xlab("Chill accumulation (Chill Portions)") +
  ylab("Frequency")

chill_simulations <-
  chill_comparison_full_seasons %>%
  filter(Data_source == "simulated")
  
ggplot(chill_simulations,
       aes(x = Chill_portions)) +
  stat_ecdf(geom = "step",
            lwd = 1.5,
            col = "blue") +
  ylab("Cumulative probability") +
  xlab("Chill accumulation (in Chill Portions)") +
  theme_bw(base_size = 20)

```


3.  Produce similar plots for the number of freezing hours (\<0°C) in
    April (or October, if your site is in the Southern Hemisphere) for
    your location of interest.
    


```{r, eval = FALSE}
library(chillR)
library(tidyverse) 

Rochester <- read.csv('data_New_York/Rochester_weather.csv')

Temp <- Rochester %>%
  temperature_generation(years = c(1998,2009),
                         sim_years = c(2001,2100))

library(dplyr)
library(magrittr)

Temperatures <- Rochester %>% 
  select(Year, Month, Day, Tmin, Tmax) %>% 
  filter(Year %in% 1998:2009) %>%
  cbind(Data_source = "observed") %>%
  rbind(
    Temp[[1]] %>% select(c(Year,
                           Month,
                           Day,
                           Tmin,
                           Tmax)) %>%
      cbind(Data_source = "simulated")
    ) %>%
  mutate(Date = as.Date(ISOdate(2000,
                                Month,
                                Day)))
df <- data.frame(
  lower =  c(-1000,    0),
  upper =  c(    0, 1000),
  weight = c(    1,    0))

freezing_hours <- function(x) step_model(x,df)

chill_observed <- Temperatures %>%
  filter(Data_source == "observed") %>%
  stack_hourly_temps(latitude = 43.15) %>%
  tempResponse(Start_JDay = 91,
               End_JDay = 120,
               models = list(Frost = freezing_hours,
                             Chill_portions = Dynamic_Model,
                             GDH = GDH))

chill_simulated <- Temperatures %>%
  filter(Data_source == "simulated") %>%
  stack_hourly_temps(latitude = 43.15) %>%
  tempResponse(Start_JDay = 91,
               End_JDay = 120,
               models=list(Frost = freezing_hours,
                           Chill_portions = Dynamic_Model,
                           GDH = GDH))

chill_comparison <-
  cbind(chill_observed,
        Data_source = "observed") %>%
  rbind(cbind(chill_simulated,
              Data_source = "simulated"))

chill_comparison_full_seasons <-
  chill_comparison %>%
  filter(Perc_complete == 100)

ggplot(chill_comparison_full_seasons,
       aes(x = Frost)) + 
  geom_histogram(binwidth = 25,
                 aes(fill = factor(Data_source))) +
  theme_bw(base_size = 10) +
  labs(fill = "Data source") +
  xlab("Frost incidence during April (hours)") +
  ylab("Frequency")

chill_simulations <-
  chill_comparison_full_seasons %>%
  filter(Data_source == "simulated")

ggplot(chill_simulations,
       aes(x = Frost)) +
  stat_ecdf(geom = "step",
            lwd = 1.5,
            col = "blue") +
  ylab("Cumulative probability") +
  xlab("Frost incidence during April (hours)") +
  theme_bw(base_size = 20)
```


------------------------------------------------------------------------

# Chapter 14: Generating historic temperature scenarios

## ***Exercises on historic temperature scenarios*** 

1. For the location you chose for previous exercises, produce historic temperature scenarios representing several years of the historic record (your choice).



```{r, eval = FALSE}

library(chillR)
library(magrittr)
require(kableExtra)

# downloading weather station list for the vicinity of Rochester
station_list <- handle_gsod(action = "list_stations",
                            location=c(-77.60, 43.15))

# downloading weather data for Greater Rochester International AP and convert it to chillR format
Rochester_weather <- handle_gsod(action = "download_weather",
                            location = station_list$chillR_code[1],
                            time_interval = c(1973,2019)) %>%
  handle_gsod()

# check record for missing data
fix_weather(Rochester_weather$'GREATER ROCHESTER INTERNATIONAL AP')$QC

Rochester_patched <- patch_daily_temperatures(
  weather = Rochester_weather$'GREATER ROCHESTER INTERNATIONAL AP',
  patch_weather = list(KA_weather))

fix_weather(Rochester_patched)$QC

# interpolating these gaps now

Rochester<-fix_weather(Rochester_patched)

Rochester_temps<-Rochester$weather

scenario_1980 <- temperature_scenario_from_records(weather = Rochester_temps,
                                                   year = 1980)

scenario_1980$'1980'$data

#what could have happened in 1980 not what happpened

temps_1980 <- temperature_generation(weather = Rochester_temps,
                                     years = c(1973, 2019),
                                     sim_years = c(2001, 2100),
                                     temperature_scenario = scenario_1980)

scenario_1996 <- temperature_scenario_from_records(weather = Rochester_temps,
                                                   year = 1996)
scenario_1996$'1996'$data

relative_scenario <- temperature_scenario_baseline_adjustment(
  baseline = scenario_1996,
  temperature_scenario = scenario_1980)

# error message here

temps_1980 <- temperature_generation(weather = Rochester_temps,
                                     years = c(1973, 2019),
                                     sim_years = c(2001, 2100),
                                     temperature_scenario = relative_scenario)

all_past_scenarios <- temperature_scenario_from_records(
  weather = Rochester_temps,
  year = c(1980,
           1990,
           2000,
           2010))

adjusted_scenarios <- temperature_scenario_baseline_adjustment(
  baseline = scenario_1996,
  temperature_scenario = all_past_scenarios)
```

```{r, eval=FALSE}

all_past_scenario_temps <- temperature_generation(
  weather = Rochester_temps,
  years = c(1973,2019),
  sim_years = c(2001,2100),
  temperature_scenario = adjusted_scenarios)

```

```{r, eval=FALSE, echo=FALSE}

save_temperature_scenarios(all_past_scenario_temps,"data_New_York","all_past_temps")
```

```{r, echo=FALSE}

all_past_scenario_temps <- load_temperature_scenarios("data_New_York","all_past_temps")
``` 

```{r, eval = FALSE}
frost_model <- function(x)
  step_model(x,
             data.frame(
               lower=c(-1000, 0),
               upper=c(0, 1000),
               weight=c(1, 0)))

models <- list(Chill_Portions = Dynamic_Model,
               GDH = GDH,
               Frost_H = frost_model)






chill_hist_scenario_list <- tempResponse_daily_list(all_past_scenario_temps,
                                                    latitude = 43.15,
                                                    Start_JDay = 305,
                                                    End_JDay = 59,
                                                    models = models)
```



2. Produce chill distributions for these scenarios and plot them.



```{r, eval = FALSE}
scenarios <- names(chill_hist_scenario_list)[1:4]


all_scenarios <- chill_hist_scenario_list[[scenarios[1]]] %>%
  mutate(scenario = as.numeric(scenarios[1]))


for (sc in scenarios[2:4])
 all_scenarios <- all_scenarios %>%
  rbind(chill_hist_scenario_list[[sc]] %>%
          cbind(
            scenario=as.numeric(sc))
        ) %>%
  filter(Perc_complete == 100)

# Let's compute the actual 'observed' chill for comparison
actual_chill <- tempResponse_daily_list(Rochester_temps,
                                        latitude = 43.15,
                                        Start_JDay = 305,
                                        End_JDay = 59,
                                        models)[[1]] %>%
  filter(Perc_complete == 100)

ggplot(data = all_scenarios,
       aes(scenario,
           Chill_Portions,
           fill = factor(scenario))) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
  ylab("Chill accumulation (Chill Portions)") +
  xlab("Scenario year") +
  theme_bw(base_size = 10) +
  ylim(c(0,90)) +
  geom_point(data = actual_chill,
             aes(End_year,
                 Chill_Portions,
                 fill = "blue"),
             col = "blue",
             show.legend = FALSE) +
  scale_fill_discrete(name = "Scenario",
                      breaks = unique(all_scenarios$scenario)) 


temperature_means <- 
  data.frame(Year = min(Rochester_temps$Year):max(Rochester_temps$Year),
             Tmin = aggregate(Rochester_temps$Tmin,
                              FUN = "mean",
                              by = list(Rochester_temps$Year))[,2],
             Tmax=aggregate(Rochester_temps$Tmax,
                            FUN = "mean",
                            by = list(Rochester_temps$Year))[,2]) %>%
  mutate(runn_mean_Tmin = runn_mean(Tmin,15),
         runn_mean_Tmax = runn_mean(Tmax,15))


Tmin_regression <- lm(Tmin ~ Year,
                      temperature_means)

Tmax_regression <- lm(Tmax ~ Year,
                      temperature_means)

temperature_means <- temperature_means %>%
  mutate(regression_Tmin = Tmin_regression$coefficients[1]+
           Tmin_regression$coefficients[2]*temperature_means$Year,
         regression_Tmax = Tmax_regression$coefficients[1]+
           Tmax_regression$coefficients[2]*temperature_means$Year
  )


ggplot(temperature_means,
       aes(Year,
           Tmin)) + 
  geom_point() + 
  geom_line(data = temperature_means,
            aes(Year,
                runn_mean_Tmin),
            lwd = 2,
            col = "blue") + 
  geom_line(data = temperature_means,
            aes(Year,
                regression_Tmin),
            lwd = 2,
            col = "red") +
  theme_bw(base_size = 15) +
  ylab("Mean monthly minimum temperature (°C)")

ggplot(temperature_means,
       aes(Year,
           Tmax)) + 
  geom_point() + 
  geom_line(data = temperature_means,
            aes(Year,
                runn_mean_Tmax),
            lwd = 2,
            col = "blue") + 
  geom_line(data = temperature_means,
            aes(Year, 
                regression_Tmax),
            lwd = 2,
            col = "red") +
  theme_bw(base_size = 15) +
  ylab("Mean monthly maximum temperature (°C)")
```




------------------------------------------------------------------------

 
# Chapter 15: Future temperature scenarios

## ***Exercises on future temperature scenarios** 

1. Briefly describe the differences between the RCPs and the SSPs.

Representative Concentration Pathways (RCPs) are climate change scenarios to project future greenhouse gas concentrations.These pathways (or trajectories) describe future greenhouse gas concentrations (not emissions) and have been formally adopted by the IPCC. The pathways describe different climate change scenarios, all of which were considered possible depending on the amount of greenhouse gases (GHG) emitted in the years to come. 

Shared Socioeconomic Pathways (SSPs) are climate change scenarios of projected socioeconomic global changes up to 2100 as defined in the IPCC Sixth Assessment Report on climate change in 2021.The SRES scenarios are "baseline" (or "reference") scenarios, which means that they do not take into account any current or future measures to limit greenhouse gas (GHG) emissions.

A major difference between both models is that RCPs focus on Emissions and Radiative Forcing while SSPs emphasize Socioeconomic Pathways.In phenology SSPs integrate societal drivers, allowing phenologists to link temperature scenarios with land use changes, habitat fragmentation, or conservation efforts.


# Chapter 16: Generating CMIP6 temperature scenarios

## ***Exercises on generating CMIP6 temperature scenarios*** 

1. Analyze the historic and future impact of climate change on two agroclimatic metrics of your choice, for the location you’ve chosen for your earlier analyses.



```{r, eval = FALSE}
require(chillR)
library(dplyr)
library(ecmwfr)
require(tidyverse)

#read Rochester_temps

Rochester_temps <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_temps.csv")

location=c(-77.60, 43.15) #Rochester

area <- c(45, -79, 40, -71)


download_cmip6_ecmwfr(
  scenarios = c("ssp126", "ssp245", "ssp370", "ssp585"),
  area = area,
  key = 'e1bd6995-c569-4df1-bbe8-3549cb586e4a',
  model = 'default',
  frequency = 'monthly',
  variable = c('Tmin',  'Tmax'),
  year_start = 2015,
  year_end = 2100)

download_baseline_cmip6_ecmwfr(
  area = area,
  key = 'e1bd6995-c569-4df1-bbe8-3549cb586e4a',
  model = 'match_downloaded',
  frequency = 'monthly',
  variable = c('Tmin', 'Tmax'),
  year_start = 1986, 
  year_end = 2014, 
  month = 1:12)

download_baseline_cmip6_ecmwfr(
  area = area,
  key = 'e1bd6995-c569-4df1-bbe8-3549cb586e4a',
  model = 'match_downloaded',
  frequency = 'monthly',
  variable = c('Tmin', 'Tmax'),
  year_start = 1986,
  year_end = 2014,
  month = 1:12)

station <- data.frame(
  station_name = c("Rochester"),
  longitude = c(-77.60),
  latitude = c(43.15))

library(ncdf4)
library(PCICt)

extracted <- extract_cmip6_data(stations = station)

head(extracted$`ssp126_AWI-CM-1-1-MR`)

change_scenarios <- 
  gen_rel_change_scenario(extracted,
                          scenarios = c(2050, 2085),
                          reference_period = c(1986:2014),
                          future_window_width = 30)
head(change_scenarios)

write.csv(change_scenarios, "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/all_change_scenarios.csv", row.names = FALSE)

change_scenarios <- read.csv("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/all_change_scenarios.csv")

scen_list <- convert_scen_information(change_scenarios)

scen_frame <- convert_scen_information(scen_list)

scen_list$Rochester$ssp126$`ACCESS-CM2`$'2050'


temps_1996 <- temperature_scenario_from_records(Rochester_temps,
                                                1996)
temps_2000 <- temperature_scenario_from_records(Rochester_temps,
                                                2000)
temps_1996
temps_2000

base <- temperature_scenario_baseline_adjustment(temps_1996,
                                                 temps_2000)

base


scen_list <- convert_scen_information(change_scenarios,
                                      give_structure = FALSE)

adjusted_list <- temperature_scenario_baseline_adjustment(base,
                                                          scen_list,
                   temperature_check_args = 
                     list(scenario_check_thresholds = c(-5, 15)))


# temps <- temperature_generation(Rochester_temps,
#                                 years = c(1973, 2019),
#                                 sim_years = c(2001, 2100),
#                                 adjusted_list,  
#                                 temperature_check_args = 
#                                   list( scenario_check_thresholds = c(-5, 15)))
# 
# save_temperature_scenarios(temps,
#                            "data_New_York/future_climate","Rochester_future")

# temps <- load_temperature_scenarios("data_New_Year/future_climate","Rochester_future_")


# now we have temperature scenarios

for(scen in 1:length(adjusted_list))
{
  if(!file.exists(paste0("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate/Rochester_future_",
                       scen,"_",
                       names(adjusted_list)[scen],".csv")) )
  {temp_temp <- temperature_generation(Rochester_temps,
                                   years = c(1973, 2019),
                                   sim_years = c(2001, 2100),
                                   adjusted_list[scen],  
                                   temperature_check_args = 
                                     list( scenario_check_thresholds = c(-5, 15)))
  write.csv(temp_temp[[1]],paste0("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate/Rochester_future_",scen,"_",names(adjusted_list)[scen],".csv"),
                             row.names=FALSE)
  print(paste("Processed object",scen,"of", length(adjusted_list)))
  
    
  }
  
}



temps <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate","Rochester_future_")

frost_model <- function(x)
  step_model(x,
             data.frame(
               lower = c(-1000, 0),
               upper = c(0, 1000),
               weight = c(1, 0)))

models <- list(Chill_Portions = Dynamic_Model,
               GDH = GDH,
               Frost_H = frost_model)

chill_future_scenario_list <- 
  tempResponse_daily_list(temps,
                          latitude = 43.15,
                          Start_JDay = 305,
                          End_JDay = 59,
                          models = models)

chill_future_scenario_list <- 
  lapply(chill_future_scenario_list,
         function(x) x %>%
           filter(Perc_complete == 100))

save_temperature_scenarios(chill_future_scenario_list,
                           "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
                           "Rochester_futurechill")

# this would be for spring frost, but we're not running this
chill_future_scenario_list_frost <- 
  tempResponse_daily_list(temps,
                          latitude = 43.15,
                          Start_JDay = 75,
                          End_JDay = 120,
                          models = list(GDH = GDH,
                                        Frost_H = frost_model))

chill_future_scenario_list_frost <- 
  lapply(chill_future_scenario_list_frost,
         function(x) x %>%
           filter(Perc_complete == 100))


save_temperature_scenarios(chill_future_scenario_list_frost,
                           "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
                           "Rochester_futurefrost")

# simulate for the observed record

Rochester_temps <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_temps.csv")

observed_chill <- tempResponse_daily_list(Rochester_temps,
                                          latitude = 43.15,
                                          Start_JDay = 305,
                                          End_JDay = 59,
                                          models = models)

write.csv(observed_chill, "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_observed_chill_305_59.csv")

# simulate chill for historic scenarios

hist_temps <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York","all_past_temps")



chill_hist_scenario_list <- tempResponse_daily_list(hist_temps,
                                                    latitude = 43.15,
                                                    Start_JDay = 305,
                                                    End_JDay = 59,
                                                    models = models)

chill_hist_scenario_list <- lapply(chill_hist_scenario_list,
                                   function(x) x %>%
                                     filter(Perc_complete == 100))

save_temperature_scenarios(chill_hist_scenario_list,
                           "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
                           "Rochester_hist_chill_305_59")

chill_future_scenario_list <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate","Rochester_futurechill")
chill_hist_scenario_list<-load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York","Rochester_hist_chill_305_59")
observed_chill <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_observed_chill_305_59.csv")


# prepare for plotting

chills <- make_climate_scenario(
  metric_summary = chill_hist_scenario_list,
  caption = "Historical",
  historic_data = observed_chill,
  time_series = TRUE)

plot_climate_scenarios(
  climate_scenario_list = chills,
  metric = "Chill_Portions",
  metric_label = "Chill (Chill Portions)")


list_ssp <- 
  strsplit(names(chill_future_scenario_list),
           '\\.') %>%
  map(2) %>%
  unlist()

list_gcm <-
  strsplit(names(chill_future_scenario_list), '\\.') %>%
  map(3) %>%
  unlist()

list_time <-
  strsplit(names(chill_future_scenario_list), '\\.') %>%
  map(4) %>%
  unlist()

SSPs <- c("ssp126", "ssp245", "ssp370", "ssp585")
Times <- c(2050, 2085)


for(SSP in SSPs)
  for(Time in Times)
  {
    
    # find all scenarios for the ssp and time
    chill <- chill_future_scenario_list[list_ssp == SSP &
                                          list_time == Time]
    names(chill) <- list_gcm[list_ssp == SSP &
                               list_time == Time]
    if(SSP == "ssp126") SSPcaption <- "SSP1"
    if(SSP == "ssp245") SSPcaption <- "SSP2"
    if(SSP == "ssp370") SSPcaption <- "SSP3"
    if(SSP == "ssp585") SSPcaption <- "SSP5"    
    chills <- chill %>% 
      make_climate_scenario(
        caption = c(SSPcaption,
                    Time),
        add_to = chills)
  }



info_chill <-
  plot_climate_scenarios(
    climate_scenario_list = chills,
    metric = "Chill_Portions",
    metric_label = "Chill (Chill Portions)",
    texcex = 1)

info_heat <-
  plot_climate_scenarios(
    climate_scenario_list = chills,
    metric = "GDH",
    metric_label = "Heat (Growing Degree Hours)",
    texcex = 1)

info_frost <- 
  plot_climate_scenarios(  
    climate_scenario_list=chills,
    metric="Frost_H",
    metric_label="Frost incidence (hours)",
    texcex=1)



info_chill[[2]]
```



------------------------------------------------------------------------

# Chapter 18: Plotting Climate Scenarios

## ***Exercises on plotting future projections*** 

1.Produce similar plots for the weather station you selected for earlier exercises.



```{r, eval = FALSE}
library(chillR)
library(tidyverse)
#library(ggpmisc)
#library(patchwork)

chill_hist_scenario_list <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York",
                                                       "Rochester_hist_chill_305_59")
actual_chill <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_observed_chill_305_59.csv")

chill_future_scenario_list <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
                                                         "Rochester_futurechill")

chills <- make_climate_scenario(
  chill_hist_scenario_list,
  caption = "Historic",
  historic_data = actual_chill,
  time_series = TRUE)

SSPs <- c("ssp126", "ssp245", "ssp370", "ssp585")
Times <- c(2050, 2085)

list_ssp <- 
  strsplit(names(chill_future_scenario_list), '\\.') %>%
  map(2) %>%
  unlist()

list_gcm <-
  strsplit(names(chill_future_scenario_list), '\\.') %>%
  map(3) %>%
  unlist()

list_time <-
  strsplit(names(chill_future_scenario_list), '\\.') %>%
  map(4) %>%
  unlist()


for(SSP in SSPs)
  for(Time in Times)
    {
    
    # find all scenarios for the ssp and time
    chill <- chill_future_scenario_list[list_ssp == SSP & list_time == Time]
    names(chill) <- list_gcm[list_ssp == SSP & list_time == Time]
    if(SSP == "ssp126") SSPcaption <- "SSP1"
    if(SSP == "ssp245") SSPcaption <- "SSP2"
    if(SSP == "ssp370") SSPcaption <- "SSP3"
    if(SSP == "ssp585") SSPcaption <- "SSP5"    
    if(Time == "2050") Time_caption <- "2050"
    if(Time == "2085") Time_caption <- "2085"
    chills <- chill %>% 
      make_climate_scenario(
        caption = c(SSPcaption,
                    Time_caption),
        add_to = chills)
}

plot_climate_scenarios(
  climate_scenario_list = chills,
  metric = "Chill_Portions",
  metric_label = "Chill (Chill Portions)",
  texcex = 1)


# We'll first process the past scenarios (element 1 of the chills list).
# Within the data element, we have a list of multiple data.frames for
# the various past scenarios.
# Using a 'for' loop, we cycle through all these data.frames.

for(nam in names(chills[[1]]$data))
  {
   # Extract the data frame.
   ch <- chills[[1]]$data[[nam]]
   # Add columns for the new information we have to add and fill them.
   ch[,"GCM"] <- "none"
   ch[,"SSP"] <- "none"
   ch[,"Year"] <- as.numeric(nam)
   
   # Now check if this is the first time we've gone through this loop.
   # If this is the first time, the ch data.frame becomes the output
   # object (past_simulated).
   # If it is not the first time ('else'), we add the current data.frame
   # to the 'past_simulated' object
  if(nam == names(chills[[1]]$data)[1])
    past_simulated <- ch else
      past_simulated <- rbind(past_simulated,
                              ch)
  }

# We add another column called 'Scenario' and label all rows as 'Historical' 
past_simulated["Scenario"] <- "Historical"

head(past_simulated)

past_simulated <- past_simulated %>% filter(Perc_complete == 100)

# We'll want to add the historic observation too, so let's simplify the
# pointer to this information for easier use later

past_observed <- chills[[1]][["historic_data"]]


head(past_observed)


# Extract future data
for(i in 2:length(chills))
  for(nam in names(chills[[i]]$data))
    {ch <- chills[[i]]$data[[nam]]
     ch[,"GCM"] <- nam
     ch[,"SSP"] <- chills[[i]]$caption[1]
     ch[,"Year"] <- chills[[i]]$caption[2]
     if(i == 2 & nam == names(chills[[i]]$data)[1])
       future_data <- ch else
         future_data <- rbind(future_data,ch)
  }


head(future_data)



metric <- "GDH"
axis_label <- "Heat (in GDH)"

# get extreme values for the axis scale


rng <- range(past_observed[[metric]],
             past_simulated[[metric]],
             future_data[[metric]])  
rng



past_plot <- ggplot() +
  geom_boxplot(data = past_simulated,
               aes_string("as.numeric(Year)",
                          metric,
                          group = "Year"),
               fill = "skyblue")

past_plot



past_plot <- past_plot +
  scale_y_continuous(
    limits = c(0, 
               round(rng[2] + rng[2]/10))) +
  labs(x = "Year", 
       y = axis_label)

past_plot


past_plot <- past_plot +
  facet_grid(~ Scenario) +
  theme_bw(base_size = 15) 
  
past_plot

  
past_plot <- past_plot +  
  theme(strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45,
                                   hjust = 1)) 

past_plot



# add historic data
past_plot <- past_plot +
  geom_point(data = past_observed,
             aes_string("End_year",
                        metric),
             col = "blue")

past_plot



y <- 2050

future_2050 <-
  ggplot(data = future_data[future_data$Year == y,]) +
  geom_boxplot(aes_string("GCM", 
                          metric, 
                          fill = "GCM"))

future_2050



future_2050 <- future_2050 +
  facet_wrap(vars(SSP), nrow = 1) +
   scale_x_discrete(labels = NULL,
                    expand = expansion(add = 1)) 


library(ggpmisc)

future_2050 <- future_2050 +
  scale_y_continuous(limits = c(0, 
                                round(round(1.1*rng[2])))) +
    geom_text_npc(aes(npcx = "center", 
                      npcy = "top",
                      label = Year),
                  size = 5)

future_2050


future_2050 <- future_2050 +
  theme_bw(base_size = 15) +
  theme(axis.ticks.y = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = "bottom",
        legend.margin = margin(0,
                               0,
                               0,
                               0,
                               "cm"),
        legend.background = element_rect(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.box.spacing = unit(0, "cm"),
        plot.subtitle = element_text(hjust = 0.5,
                                     vjust = -1,
                                     size = 15 * 1.05,
                                     face = "bold")) 

future_2050


future_plot_list <- list()

time_points <- c(2050, 2085)

for(y in time_points)
{
  future_plot_list[[which(y == time_points)]] <-
    ggplot(data = future_data[which(future_data$Year==y),]) +
    geom_boxplot(aes_string("GCM",
                            metric,
                            fill="GCM")) +
    facet_wrap(vars(SSP), nrow = 1) +
    scale_x_discrete(labels = NULL,
                     expand = expansion(add = 1)) +
    scale_y_continuous(limits = c(0, 
                                  round(round(1.1*rng[2])))) +
    geom_text_npc(aes(npcx = "center",
                      npcy = "top", 
                      label = Year),
                  size = 5) +
    theme_bw(base_size = 15) +
    theme(axis.ticks.y = element_blank(),
          axis.text = element_blank(),
          axis.title = element_blank(),
          legend.position = "bottom",
          legend.margin = margin(0, 
                                 0, 
                                 0, 
                                 0, 
                                 "cm"),
          legend.background = element_rect(),
          strip.background = element_blank(),
          strip.text = element_text(face = "bold"),
          legend.box.spacing = unit(0, "cm"),
          plot.subtitle = element_text(
            hjust = 0.5,
            vjust = -1,
            size = 15 * 1.05,
            face = "bold")) 
}

future_plot_list


library(patchwork)

both_plots <- past_plot + future_plot_list

both_plots



plot <- both_plots +
           plot_layout(guides = "collect",
                       widths = c(1,
                                  rep(1.8,
                                      length(future_plot_list))))
         


plot <- plot & theme(legend.position = "bottom",
                     legend.text = element_text(size = 8),
                     legend.title = element_text(size = 10),
                     axis.title.x = element_blank())


plot


         
metric <- "Chill_Portions"
axis_label <- "Chill (in CP)"

# get extreme values for the axis scale

rng <- range(past_observed[[metric]],
             past_simulated[[metric]],
             future_data[[metric]])  
past_plot <- ggplot() +
  geom_boxplot(data = past_simulated,
               aes_string("as.numeric(Year)",
                          metric,group="Year"),
               fill="skyblue") +
  scale_y_continuous(limits = c(0, 
                                round(round(1.1*rng[2])))) +
  labs(x = "Year", y = axis_label) +
  facet_grid(~ Scenario) +
  theme_bw(base_size = 15) +  
  theme(strip.background = element_blank(),
           strip.text = element_text(face = "bold"),
           axis.text.x = element_text(angle=45, hjust=1)) +
  geom_point(data = past_observed,
             aes_string("End_year",
                        metric),
             col="blue")

future_plot_list <- list()

for(y in c(2050,
           2085))
{
  future_plot_list[[which(y == c(2050,2085))]] <-
    ggplot(data = future_data[which(future_data$Year==y),]) +
    geom_boxplot(aes_string("GCM", 
                            metric, 
                            fill="GCM")) +
  facet_wrap(vars(SSP), nrow = 1) +
   scale_x_discrete(labels = NULL,
                    expand = expansion(add = 1)) +
  scale_y_continuous(limits = c(0,
                                round(round(1.1*rng[2])))) +
    geom_text_npc(aes(npcx = "center", 
                      npcy = "top", 
                      label = Year),
                  size = 5) +
  theme_bw(base_size = 15) +
  theme(axis.ticks.y = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = "bottom",
        legend.margin = margin(0,
                               0, 
                               0,
                               0, 
                               "cm"),
        legend.background = element_rect(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.box.spacing = unit(0, "cm"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     vjust = -1,
                                     size = 15 * 1.05,
                                     face = "bold")) 
}

plot <- (past_plot +
           future_plot_list +
           plot_layout(guides = "collect",
                       widths = c(1,rep(1.8,length(future_plot_list))))
         ) & theme(legend.position = "bottom",
                   legend.text = element_text(size = 8),
                   legend.title = element_text(size = 10),
                   axis.title.x=element_blank())
plot


         
metric <- "Frost_H"
axis_label <- "Frost duration (in hours)"

# get extreme values for the axis scale

rng <- range(past_observed[[metric]],
             past_simulated[[metric]],
             future_data[[metric]])  
past_plot <- ggplot() +
  geom_boxplot(data = past_simulated,
               aes_string("as.numeric(Year)",
                          metric,group="Year"),
               fill="skyblue") +
  scale_y_continuous(limits = c(0, 
                                round(round(1.1*rng[2])))) +
  labs(x = "Year", y = axis_label) +
  facet_grid(~ Scenario) +
  theme_bw(base_size = 15) +  
  theme(strip.background = element_blank(),
           strip.text = element_text(face = "bold"),
           axis.text.x = element_text(angle=45, hjust=1)) +
  geom_point(data = past_observed,
             aes_string("End_year",
                        metric),
             col="blue")

future_plot_list <- list()

for(y in c(2050,
           2085))
{
  future_plot_list[[which(y == c(2050,2085))]] <-
    ggplot(data = future_data[which(future_data$Year==y),]) +
    geom_boxplot(aes_string("GCM", 
                            metric, 
                            fill="GCM")) +
  facet_wrap(vars(SSP), nrow = 1) +
   scale_x_discrete(labels = NULL,
                    expand = expansion(add = 1)) +
  scale_y_continuous(limits = c(0,
                                round(round(1.1*rng[2])))) +
    geom_text_npc(aes(npcx = "center", 
                      npcy = "top", 
                      label = Year),
                  size = 5) +
  theme_bw(base_size = 15) +
  theme(axis.ticks.y = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = "bottom",
        legend.margin = margin(0,
                               0, 
                               0,
                               0, 
                               "cm"),
        legend.background = element_rect(),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.box.spacing = unit(0, "cm"),
        plot.subtitle = element_text(hjust = 0.5, 
                                     vjust = -1,
                                     size = 15 * 1.05,
                                     face = "bold")) 
}

plot <- (past_plot +
           future_plot_list +
           plot_layout(guides = "collect",
                       widths = c(1,rep(1.8,length(future_plot_list))))
         ) & theme(legend.position = "bottom",
                   legend.text = element_text(size = 8),
                   legend.title = element_text(size = 10),
                   axis.title.x=element_blank())
plot


plot_scenarios_gg <- function(past_observed,
                              past_simulated,
                              future_data,
                              metric,
                              axis_label,
                              time_points)
{
  rng <- range(past_observed[[metric]],
               past_simulated[[metric]],
               future_data[[metric]])  
  past_plot <- ggplot() +
    geom_boxplot(data = past_simulated,
                 aes_string("as.numeric(Year)",
                            metric,
                            group="Year"),
                 fill="skyblue") +
    scale_y_continuous(limits = c(0, 
                                  round(round(1.1*rng[2])))) +
    labs(x = "Year", y = axis_label) +
    facet_grid(~ Scenario) +
    theme_bw(base_size = 15) +  
    theme(strip.background = element_blank(),
          strip.text = element_text(face = "bold"),
          axis.text.x = element_text(angle=45, 
                                     hjust=1)) +
    geom_point(data = past_observed,
               aes_string("End_year",
                          metric),
               col="blue")
  
  future_plot_list <- list()
  
  for(y in time_points)
  {
    future_plot_list[[which(y == time_points)]] <-
      ggplot(data = future_data[which(future_data$Year==y),]) +
      geom_boxplot(aes_string("GCM", 
                              metric, 
                              fill="GCM")) +
      facet_wrap(vars(SSP), nrow = 1) +
      scale_x_discrete(labels = NULL,
                       expand = expansion(add = 1)) +
      scale_y_continuous(limits = c(0, 
                                    round(round(1.1*rng[2])))) +
      geom_text_npc(aes(npcx = "center",
                        npcy = "top",
                        label = Year),
                    size = 5) +
      theme_bw(base_size = 15) +
      theme(axis.ticks.y = element_blank(),
            axis.text = element_blank(),
            axis.title = element_blank(),
            legend.position = "bottom",
            legend.margin = margin(0,
                                   0, 
                                   0, 
                                   0, 
                                   "cm"),
            legend.background = element_rect(),
            strip.background = element_blank(),
            strip.text = element_text(face = "bold"),
            legend.box.spacing = unit(0, "cm"),
            plot.subtitle = element_text(hjust = 0.5,
                                         vjust = -1,
                                         size = 15 * 1.05,
                                         face = "bold")) 
  }
  
  plot <- (past_plot +
             future_plot_list +
             plot_layout(guides = "collect",
                         widths = c(1,rep(1.8,length(future_plot_list))))
           ) & theme(legend.position = "bottom",
                     legend.text = element_text(size=8),
                     legend.title = element_text(size=10),
                     axis.title.x=element_blank())
  plot
  
}




plot_scenarios_gg(past_observed = past_observed,
                  past_simulated = past_simulated,
                  future_data = future_data,
                  metric = "GDH",
                  axis_label = "Heat (in Growing Degree Hours)",
                  time_points = c(2050, 2085))
```

```{r, eval = FALSE}
plot_scenarios_gg(past_observed = past_observed,
                  past_simulated = past_simulated,
                  future_data = future_data,
                  metric = "Chill_Portions",
                  axis_label = "Chill (in Chill Portions)",
                  time_points = c(2050, 2085))
```

```{r, eval = FALSE}
plot_scenarios_gg(past_observed = past_observed,
                  past_simulated = past_simulated,
                  future_data = future_data,
                  metric = "Frost_H",
                  axis_label = "Frost duration (in hours)",
                  time_points = c(2050, 2085))

ggsave("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_frost_plot.png", 
       width = 10,
       height = 8,
       dpi = 600)

```


------------------------------------------------------------------------

# Chapter 19: Chill model comparison

## ***Exercises on chill model comparison*** 

1.Produce similar plots for the weather station you selected for earlier exercises.



```{r, eval = FALSE}

 library(chillR)
 library(tidyverse)
 library(colorRamps)
 library(patchwork)
 library(gganimate)
 
 SSPs <- c("ssp126", "ssp245", "ssp370", "ssp585")
 Times <- c(2050, 2085)
 
 library(chillR)
 library(devtools)
 install_github("EduardoFernandezC/dormancyR")
 library(dormancyR)
 
 hourly_models <- list( Chilling_units = chilling_units,
      Low_chill = low_chill_model,
      Modified_Utah = modified_utah_model,
      North_Carolina = north_carolina_model,
      Positive_Utah = positive_utah_model,
      Chilling_Hours = Chilling_Hours,
      Utah_Chill_Units = Utah_Model,
      Chill_Portions = Dynamic_Model)
 
  daily_models <- list(Rate_of_Chill = rate_of_chill,
                       Chill_Days = chill_days,
                       Exponential_Chill = exponential_chill,
                      Triangular_Chill_Haninnen = triangular_chill_1,
                     Triangular_Chill_Legave = triangular_chill_2)

metrics <- c(names(daily_models),
             names(hourly_models))

model_labels = c("Rate of Chill",
                 "Chill Days",
                 "Exponential Chill",
                 "Triangular Chill (Häninnen)",
                 "Triangular Chill (Legave)",
                 "Chilling Units",
                 "Low-Chill Chill Units",
                 "Modified Utah Chill Units",
                 "North Carolina Chill Units",
                 "Positive Utah Chill Units",
                 "Chilling Hours",
                 "Utah Chill Units",
                 "Chill Portions")


data.frame(Metric=model_labels,'Function name'=metrics)


data.frame(Metric=model_labels,'Function name'=metrics)

Rochester_temps <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_temps.csv")

Temps <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York",
                                    "all_past_temps")




Start_JDay <- 305
End_JDay <- 59

daily_models_past_scenarios <-
  tempResponse_list_daily(Temps,
                          Start_JDay = Start_JDay,
                          End_JDay = End_JDay,
                          models = daily_models) # list of daily temperatures function for min and max temps

daily_models_past_scenarios <- lapply(
  daily_models_past_scenarios,
  function(x) x[which(x$Perc_complete>90),]) # allows us to apply models
# total of 99 seasons

hourly_models_past_scenarios <-
  tempResponse_daily_list(Temps,
                          latitude = 43.156,
                          Start_JDay = Start_JDay,
                          End_JDay = End_JDay,
                          models = hourly_models,
                          misstolerance = 10)

past_scenarios <- daily_models_past_scenarios # combine the two models

past_scenarios <- lapply(
  names(past_scenarios),
  function(x)
    cbind(past_scenarios[[x]],
          hourly_models_past_scenarios[[x]][,names(hourly_models)]))

names(past_scenarios) <- names(daily_models_past_scenarios)

daily_models_observed <-
  tempResponse_daily(Rochester_temps,
                     Start_JDay = Start_JDay,
                     End_JDay = End_JDay,
                     models = daily_models)

daily_models_observed <-
  daily_models_observed[which(daily_models_observed$Perc_complete>90),]

hourly_models_observed <-
  tempResponse_daily_list(Rochester_temps,
                          latitude= 43.156,
                          Start_JDay = Start_JDay,
                          End_JDay = End_JDay,
                          models = hourly_models,
                          misstolerance = 10)
# run from here later
past_observed <- cbind(
  daily_models_observed,
  hourly_models_observed[[1]][,names(hourly_models)])

save_temperature_scenarios(past_scenarios,
                           "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
                           "Rochester_multichill_305_59_historic")
write.csv(past_observed,
          "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate/Rochester_multichill_305_59_observed.csv",
          row.names=FALSE)



future_temps <- load_temperature_scenarios("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate","Rochester_future_")

SSPs <- c("ssp126", "ssp245", "ssp370", "ssp585")
Times <- c(2050, 2085)


list_ssp <-
  strsplit(names(future_temps), '\\.') %>%
  map(2) %>%
  unlist()

list_gcm <-
  strsplit(names(future_temps), '\\.') %>%
  map(3) %>%
  unlist()

list_time <-
  strsplit(names(future_temps), '\\.') %>%
  map(4) %>%
  unlist()


for(SSP in SSPs)
  for(Time in Times)
    {
    Temps <- future_temps[list_ssp == SSP & list_time == Time]
    names(Temps) <- list_gcm[list_ssp == SSP & list_time == Time]
    daily_models_future_scenarios <- tempResponse_list_daily(
      Temps,
      Start_JDay = Start_JDay,
      End_JDay = End_JDay,
      models = daily_models)
    daily_models_future_scenarios<-lapply(
      daily_models_future_scenarios,
      function(x) x[which(x$Perc_complete>90),])
    hourly_models_future_scenarios<-
      tempResponse_daily_list(
        Temps,
        latitude = 43.156,
        Start_JDay = Start_JDay,
        End_JDay = End_JDay,
        models=hourly_models,
        misstolerance = 10)

    future_scenarios <- daily_models_future_scenarios

    future_scenarios <- lapply(
      names(future_scenarios),
      function(x)
        cbind(future_scenarios[[x]],
              hourly_models_future_scenarios[[x]][,names(hourly_models)]))
    names(future_scenarios)<-names(daily_models_future_scenarios)

    chill<-future_scenarios

    save_temperature_scenarios(
      chill,
      "data_New_York/future_climate",
      paste0("Rochester_multichill_305_59_",Time,"_",SSP))
}

chill_past_scenarios <- load_temperature_scenarios(
  "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
  "Rochester_multichill_305_59_historic")

chill_observed <-
  read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate/Rochester_multichill_305_59_observed.csv")


chills <- make_climate_scenario(chill_past_scenarios,
                                caption = "Historic",
                                historic_data = chill_observed,
                                time_series = TRUE)

for(SSP in SSPs)
  for(Time in Times)
    {
    chill <- load_temperature_scenarios(
      "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/future_climate",
      paste0("Rochester_multichill_305_59_",Time,"_",SSP))
    if(SSP == "ssp126") SSPcaption <- "SSP1"
    if(SSP == "ssp245") SSPcaption <- "SSP2"
    if(SSP == "ssp370") SSPcaption <- "SSP3"
    if(SSP == "ssp585") SSPcaption <- "SSP5"
    if(Time == "2050") Time_caption <- "2050"
    if(Time == "2085") Time_caption <- "2085"

    chills <- make_climate_scenario(chill,
                                    caption = c(SSPcaption,
                                                Time_caption),
                                    add_to = chills)
}


plot_climate_scenarios(chills,
                       metric="Rate_of_Chill",
                       metric_label="Rate of Chill",
                       year_name="End_Year")


for(i in 1:length(chills))
   {ch <- chills[[i]]
   if(ch$caption[1] == "Historic")
     {GCMs <- rep("none",length(names(ch$data)))
      SSPs <- rep("none",length(names(ch$data)))
      Years <- as.numeric(ch$labels)
      Scenario <- rep("Historic",
                      length(names(ch$data)))} else
                        {GCMs <- names(ch$data)
                        SSPs <- rep(ch$caption[1],
                                    length(names(ch$data)))
                        Years <- rep(as.numeric(ch$caption[2]),
                                     length(names(ch$data)))
                        Scenario <- rep("Future",
                                        length(names(ch$data)))}
   for(nam in names(ch$data))
     {for(met in metrics)
       {temp_res <-
         data.frame(Metric = met,
                    GCM = GCMs[which(nam == names(ch$data))],
                    SSP = SSPs[which(nam == names(ch$data))],
                    Year = Years[which(nam == names(ch$data))],
                    Result = quantile(ch$data[[nam]][,met],0.1), # 10% quantile
                    Scenario = Scenario[which(nam == names(ch$data))])
       if(i == 1 & nam == names(ch$data)[1] & met == metrics[1])
         results <- temp_res else
           results <- rbind(results,
                            temp_res)
         }
     }
   }

for(met in metrics)
  results[which(results$Metric == met),"SWC"] <-
    results[which(results$Metric == met),"Result"]/
      results[which(results$Metric == met & results$Year == 1980),
              "Result"]-1

rng = range(results$SWC)

p_future <- ggplot(results[which(!results$GCM == "none"),],
                   aes(GCM,
                       y = factor(Metric,
                                  levels = metrics),
                       fill = SWC)) +
  geom_tile()

p_future


p_future <-
  p_future +
  facet_grid(SSP ~ Year)

p_future

p_future <-
  p_future +
  theme_bw(base_size = 10) +
  theme(axis.text = element_text(size = 6))

p_future

library(colorRamps)
p_future <-
  p_future +
  scale_fill_gradientn(colours = rev(matlab.like(15)),
                       labels = scales::percent,
                       limits = rng)

p_future


p_future <-
  p_future  +
  theme(axis.text.x = element_text(angle = 75,
                                   hjust = 1,
                                   vjust = 1)) +
  labs(fill = "Change in\nSafe Winter Chill\nsince 1975") +
  scale_y_discrete(labels = model_labels) +
  ylab("Chill metric")

p_future




p_past<-
  ggplot(results[which(results$GCM == "none"),],
         aes(Year,
             y = factor(Metric,
                        levels=metrics),
             fill = SWC)) +
  geom_tile()

p_past<-
  p_past +
  theme_bw(base_size = 10) +
  theme(axis.text = element_text(size = 6))

p_past<-
  p_past +
  scale_fill_gradientn(colours = rev(matlab.like(15)),
                       labels = scales::percent,
                       limits = rng)

p_past<-
  p_past +
  scale_x_continuous(position = "top")

p_past<-
  p_past +
  labs(fill = "Change in\nSafe Winter Chill\nsince 1975") +
  scale_y_discrete(labels = model_labels) +
  ylab("Chill metric")

p_past


library(patchwork)

chill_comp_plot<-
  (p_past +
     p_future +
     plot_layout(guides = "collect",
                 nrow = 2,
                 heights = c(1,3))) &
  theme(legend.position = "right",
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"))

chill_comp_plot
hist_results <- results[which(results$GCM == "none"),]
hist_results$SSP <- "SSP1"
hist_results_2 <- hist_results
hist_results_2$SSP <- "SSP2"
hist_results_3 <- hist_results
hist_results_3$SSP <- "SSP3"
hist_results_4 <- hist_results
hist_results_4$SSP <- "SSP5"
hist_results <- rbind(hist_results,
                      hist_results_2,
                      hist_results_3,
                      hist_results_4)

future_results <- results[which(!results$GCM == "none"),]

GCM_aggregate <- aggregate(
  future_results$SWC,
  by=list(future_results$Metric,
          future_results$SSP,
          future_results$Year),
  FUN=mean)

colnames(GCM_aggregate) <- c("Metric",
                             "SSP",
                             "Year",
                             "SWC")

SSP_Time_series<-rbind(hist_results[,c("Metric",
                                       "SSP",
                                       "Year",
                                       "SWC")],
                       GCM_aggregate)



SSP_Time_series$Year <- as.numeric(SSP_Time_series$Year)

chill_change_plot<-
  ggplot(data = SSP_Time_series,
         aes(x = Year,
             y = SWC,
             col = factor(Metric,
                          levels = metrics))) +
  geom_line(lwd = 1.3) +
  facet_wrap(~SSP,
             nrow = 3) +
  theme_bw(base_size = 10) +
  labs(col = "Change in\nSafe Winter Chill\nsince 1980") +
  scale_color_discrete(labels = model_labels) +
  scale_y_continuous(labels = scales::percent) +
  theme(strip.background = element_blank(),
        strip.text = element_text(face = "bold")) +
  ylab("Safe Winter Chill")

chill_change_plot

library(gganimate)
library(gifski)
library(png)
library(transformr)

ccp<-chill_change_plot +
  transition_reveal(Year)

# trying out different numbers of frames per second

animate(ccp, fps=1)
anim_save("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/chill_comparison_animation_1.gif",
          animation = last_animation())

animate(ccp, fps=100)
anim_save("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/chill_comparison_animation_100.gif",
          animation = last_animation())
```


------------------------------------------------------------------------

# Chapter 20: Simple Phenology Analysis

## ***Exercises on simple phenology analysis*** 

1. Provide a brief narrative describing what p-hacking is, and why this is a problematic approach to data analysis.

P-hacking, (data fishing), is the manipulation of data analysis to obtain statistically significant results, often by repeatedly testing different hypotheses, adjusting variables, or selectively reporting findings until a desired p-value (typically < 0.05) is achieved. 

This is problematic because it increases the likelihood of false positives—results that appear significant but are actually due to chance and it causes over-fitting during data analysis. 

2. Provide a sketch of your causal understanding of the relationship between temperature and bloom dates.

Temperature - Time
Climate change has caused:
- Warmer winter = delay in bloom dates
- Rising spring temperature = advanced bloom dates

Temperatures have been rising over time and phenology has advanced over time so later years generally feature earlier bloom dates.

3. What do we need to know to build a process-based model from this?

Regression equation isn't very useful for this process.

------------------------------------------------------------------------

# Chapter 21: Delineating temperature response phases with PLS regression

## ***Exercises on chill model comparison*** 

1. Briefly explain why you shouldn’t take the results of a PLS regression analysis between temperature and phenology at face value. 

PLS should not be used as a data mining tool but in conjuction with a theory on how the system works to detect meaningful pattterns. 


2. What do you need in addition in order to make sense of such outputs?
Replicate the PLS analysis for the Roter Boskoop dataset that you used in a previous lesson.



```{r}
library(chillR)
library(tidyverse)

Roter_first <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Roter_Boskoop_bloom_1958_2019.csv.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay)


head(Roter_first)


KA_temps <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv") %>%
  make_JDay()

head(KA_temps)

PLS_results <- PLS_pheno(KA_temps,
                         Roter_first)


head(PLS_results$PLS_summary)

plot_PLS(PLS_results,
         PLS_results_path = "PLS_out")
```

```{r}
library(ggplot2)

PLS_gg <- PLS_results$PLS_summary %>%
  mutate(Month = trunc(Date / 100),
         Day = Date - Month * 100,
         Date = NULL) 

PLS_gg$Date <- ISOdate(2002, 
                       PLS_gg$Month, 
                       PLS_gg$Day)
PLS_gg$Date[PLS_gg$JDay <= 0] <-
  ISOdate(2001, 
          PLS_gg$Month[PLS_gg$JDay <= 0], 
          PLS_gg$Day[PLS_gg$JDay <= 0])

PLS_gg <- PLS_gg %>%
  mutate(VIP_importance = VIP >= 0.8,
         VIP_Coeff = factor(sign(Coef) * VIP_importance))

VIP_plot<- ggplot(PLS_gg,
                  aes(x = Date,
                      y = VIP)) +
  geom_bar(stat='identity',
           aes(fill = VIP_importance))

VIP_plot <- VIP_plot +
  scale_fill_manual(name="VIP", 
                    labels = c("<0.8",
                               ">0.8"), 
                    values = c("FALSE"="grey",
                               "TRUE"="blue")) +
  theme_bw(base_size=15) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank() )

VIP_plot

coeff_plot <- ggplot(PLS_gg,
                     aes(x = Date,
                         y = Coef)) +
  geom_bar(stat ='identity',
           aes(fill = VIP_Coeff)) +
  scale_fill_manual(name = "Effect direction", 
                    labels = c("Advancing",
                               "Unimportant",
                               "Delaying"), 
                    values = c("-1" = "red", 
                               "0" = "grey",
                               "1" = "dark green")) +
  theme_bw(base_size = 15) +
  ylab("PLS coefficient") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank() )

coeff_plot

temp_plot <- ggplot(PLS_gg) +
  geom_ribbon(aes(x = Date,
                  ymin = Tmean - Tstdev,
                  ymax = Tmean + Tstdev),
              fill = "grey") +
  geom_ribbon(aes(x = Date,
                  ymin = Tmean - Tstdev * (VIP_Coeff == -1),
                  ymax = Tmean + Tstdev * (VIP_Coeff == -1)),
              fill = "red") +
  geom_ribbon(aes(x = Date,
                  ymin = Tmean - Tstdev * (VIP_Coeff == 1),
                  ymax = Tmean + Tstdev * (VIP_Coeff == 1)),
              fill = "dark green") +
  geom_line(aes(x = Date,
                y = Tmean)) +
  theme_bw(base_size = 15) +
  ylab(expression(paste(T[mean]," (°C)")))

temp_plot

library(patchwork)

plot<- (VIP_plot +
          coeff_plot +
          temp_plot +
          plot_layout(ncol = 1,
            guides = "collect")
        ) & theme(legend.position = "right",
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 10),
                  axis.title.x = element_blank())

plot


ggplot_PLS <- function(PLS_results)
{
  library(ggplot2)
  PLS_gg <- PLS_results$PLS_summary %>%
    mutate(Month = trunc(Date / 100),
           Day = Date - Month * 100,
           Date = NULL) 
  
  PLS_gg$Date <- ISOdate(2002, 
                         PLS_gg$Month, 
                         PLS_gg$Day)
  
  PLS_gg$Date[PLS_gg$JDay <= 0] <-
    ISOdate(2001, 
            PLS_gg$Month[PLS_gg$JDay <= 0], 
            PLS_gg$Day[PLS_gg$JDay <= 0])
  
  PLS_gg <- PLS_gg %>%
    mutate(VIP_importance = VIP >= 0.8,
           VIP_Coeff = factor(sign(Coef) * VIP_importance))
  
  VIP_plot<- ggplot(PLS_gg,aes(x=Date,y=VIP)) +
    geom_bar(stat='identity',aes(fill=VIP>0.8))
  
  VIP_plot <- VIP_plot +
    scale_fill_manual(name="VIP", 
                      labels = c("<0.8", ">0.8"), 
                      values = c("FALSE"="grey", "TRUE"="blue")) +
    theme_bw(base_size=15) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank())
  
  coeff_plot <- ggplot(PLS_gg,
                       aes(x = Date,
                           y = Coef)) +
    geom_bar(stat ='identity',
             aes(fill = VIP_Coeff)) +
    scale_fill_manual(name = "Effect direction", 
                      labels = c("Advancing",
                                 "Unimportant",
                                 "Delaying"), 
                      values = c("-1" = "red", 
                                 "0" = "grey",
                                 "1" = "dark green")) +
    theme_bw(base_size = 15) +
    ylab("PLS coefficient") +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank())
  
  temp_plot <- ggplot(PLS_gg) +
    geom_ribbon(aes(x = Date,
                    ymin = Tmean - Tstdev,
                    ymax = Tmean + Tstdev),
                fill = "grey") +
    geom_ribbon(aes(x = Date,
                    ymin = Tmean - Tstdev * (VIP_Coeff == -1),
                    ymax = Tmean + Tstdev * (VIP_Coeff == -1)),
                fill = "red") +
    geom_ribbon(aes(x = Date,
                    ymin = Tmean - Tstdev * (VIP_Coeff == 1),
                    ymax = Tmean + Tstdev * (VIP_Coeff == 1)),
                fill = "dark green") +
    geom_line(aes(x = Date,
                  y = Tmean)) +
    theme_bw(base_size = 15) +
    ylab(expression(paste(T[mean]," (°C)")))
  
  library(patchwork)
  
  plot<- (VIP_plot +
            coeff_plot +
            temp_plot +
            plot_layout(ncol=1,
                        guides = "collect")
          ) & theme(legend.position = "right",
                    legend.text = element_text(size = 8),
                    legend.title = element_text(size = 10),
                    axis.title.x = element_blank())
  
  plot}

ggplot_PLS(PLS_results)

```




3. Write down your thoughts on why we’re not seeing the temperature response pattern we may have expected. What happened to the chill response?

PLS responded to temperatures indicating greater heat accumulation which shows early bloom however this is absent for chill accumulation because they are not monotonically related.
------------------------------------------------------------------------

# Chapter 22: Successes and limitations of PLS regression analysis

## ***Exercises on chill model comparison*** 

1. Briefly explain in what climatic settings we can expect PLS regression to detect the chilling phase - and in what settings this probably won’t work.

In locations such as Davis in California, warm temperatures in winter reduces chill accumulation. While in other locations such as Klein-Altendorf and Beijing, when relatively cold, warming may increase the chill.When temperatures are relatively high, chill accumulation would be reduced by warming. At these two locations, there is no monotonic relationship between temperature and chill accumulation. Therefore, PLS would not produce clear results.


2. How could we overcome this problem?

PLS regression failed to pick up the chilling period in relatively cold locations is that there is no monotonic relationship between temperature and chill effectiveness.

To overcome this problem, we need to convert temperature into something that is monotonically related to chill accumulation. Maybe we can make use of the chill models we already learned about

------------------------------------------------------------------------

# Chapter 23: PLS regression with agroclimatic metrics

## ***Exercises on Chill model comparison*** 

1. Repeat the PLS_chill_force procedure for the ‘Roter Boskoop’ dataset. Include plots of daily chill and heat accumulation.



```{r}
library(chillR)
library(magrittr)

temps_hourly <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv") %>%
  stack_hourly_temps(latitude = 43.1)


head(temps_hourly$hourtemps)

daychill <- daily_chill(hourtemps = temps_hourly,
                        running_mean = 1,
                        models = list(
                          Chilling_Hours = Chilling_Hours,
                          Utah_Chill_Units = Utah_Model,
                          Chill_Portions = Dynamic_Model,
                          GDH = GDH)
                        )

head(daychill$daily_chill)

dc <- make_daily_chill_plot2(daychill,
                             metrics = c("Chill_Portions"),
                             cumulative = FALSE,
                             startdate = 300,
                             enddate = 30,
                             focusyears = c(2008,2018), 
                             metriclabels = "Chill Portions")



dc <- make_daily_chill_plot2(daychill,
                             metrics = c("Chill_Portions"),
                             cumulative = TRUE,
                             startdate = 300,
                             enddate = 30,
                             focusyears = c(2008),
                             metriclabels = "Chill Portions")
library(dplyr)

Roter_Boskoop <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Roter_Boskoop_bloom_1958_2019.csv.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, 
         JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay) 


plscf <- PLS_chill_force(daily_chill_obj = daychill,
                         bio_data_frame = Roter_Boskoop,
                         split_month = 6,
                         chill_models = "Chill_Portions",
                         heat_models = "GDH")

head(plscf$Chill_Portions$GDH$PLS_summary)

```



2. Run PLS_chill_force analyses for all three major chill models. Delineate your best estimates of chilling and forcing phases for all of them.



```{r}
plot_PLS(plscf,
         PLS_results_path = "data_New_York/plscf_outputs_NY")

plscf <- PLS_chill_force(daily_chill_obj = daychill,
                         bio_data_frame = Roter_Boskoop,
                         split_month = 6,
                         chill_models = "Chill_Portions",
                         heat_models = "GDH",
                         runn_means = 11)




plot_PLS(plscf,
         PLS_results_path = "data_New_York/plscf_outputs_NY_11days")



plot_PLS(plscf,
         PLS_results_path = "data_New_York/plscf_outputs_NY_11days_periods",
         add_chill = c(-48,62),
         add_heat = c(-5,105.5))

PLS_gg <- plscf$Chill_Portions$GDH$PLS_summary %>%
  mutate(Month = trunc(Date/100),
         Day = Date - Month * 100,
         Date = ISOdate(2002,
                        Month,
                        Day))

PLS_gg[PLS_gg$JDay <= 0,"Date"]<-
  ISOdate(2001,
          PLS_gg$Month[PLS_gg$JDay <= 0],
          PLS_gg$Day[PLS_gg$JDay <= 0])

PLS_gg <- PLS_gg %>%
  mutate(VIP_importance = VIP >= 0.8,
         VIP_Coeff = factor(sign(Coef) * VIP_importance))

chill_start_JDay <- -48
chill_end_JDay <- 62
heat_start_JDay <- -5
heat_end_JDay <- 105.5

chill_start_date <- ISOdate(2001,
                            12,
                            31) + chill_start_JDay * 24 * 3600
chill_end_date <- ISOdate(2001,
                          12,
                          31) + chill_end_JDay * 24 * 3600
heat_start_date <- ISOdate(2001,
                           12,
                           31) + heat_start_JDay * 24 * 3600
heat_end_date <- ISOdate(2001,
                         12,
                         31) + heat_end_JDay * 24 * 3600

library(ggplot2)

temp_plot <- ggplot(PLS_gg,
                    x = Date) +
  annotate("rect",
           xmin = chill_start_date,
           xmax = chill_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "blue") +
  annotate("rect",
           xmin = heat_start_date,
           xmax = heat_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "red") +
  annotate("rect",
           xmin = ISOdate(2001,
                          12,
                          31) +
             min(plscf$pheno$pheno,
                 na.rm = TRUE) * 24 * 3600,
           xmax = ISOdate(2001,
                          12,
                          31) +
             max(plscf$pheno$pheno,
                 na.rm = TRUE) * 24 * 3600,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "black") +
  geom_vline(xintercept = ISOdate(2001,
                                  12,
                                  31) +
               median(plscf$pheno$pheno,
                      na.rm = TRUE) * 24 * 3600,
             linetype = "dashed") +
  geom_ribbon(aes(x = Date,
                  ymin = MetricMean - MetricStdev ,
                  ymax = MetricMean + MetricStdev),
              fill="grey") +
  geom_ribbon(aes(x = Date,
                  ymin = MetricMean - MetricStdev * (VIP_Coeff == -1),
                  ymax = MetricMean + MetricStdev * (VIP_Coeff == -1)),
              fill = "red") +
  geom_ribbon(aes(x = Date,
                  ymin = MetricMean - MetricStdev * (VIP_Coeff == 1),
                  ymax = MetricMean + MetricStdev * (VIP_Coeff == 1)),
              fill = "dark green") +
  geom_line(aes(x = Date,
                y = MetricMean ))

temp_plot

temp_plot <- temp_plot +
  facet_wrap(vars(Type),
             scales = "free_y",
             strip.position = "left",
             labeller =
               labeller(Type = as_labeller(
               c(Chill = "Chill (CP)",
                 Heat = "Heat (GDH)")))) +
  ggtitle("Daily chill and heat accumulation rates") +
  theme_bw(base_size = 15) + 
  theme(strip.background = element_blank(),
        strip.placement = "outside",
        strip.text.y = element_text(size =12),
        plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank()
        )

temp_plot



VIP_plot<- ggplot(PLS_gg,
                  aes(x = Date,
                      y = VIP)) +
  annotate("rect",
           xmin = chill_start_date,
           xmax = chill_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "blue") +
  annotate("rect",
           xmin = heat_start_date,
           xmax = heat_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "red") +
  annotate("rect",
           xmin = ISOdate(2001,
                          12,
                          31) +
             min(plscf$pheno$pheno,
                 na.rm = TRUE) * 24 * 3600,
           xmax = ISOdate(2001,
                          12,
                          31) +
             max(plscf$pheno$pheno,
                 na.rm = TRUE) * 24 * 3600,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "black") +
  geom_vline(xintercept = ISOdate(2001,
                                  12,
                                  31) +
               median(plscf$pheno$pheno,
                      na.rm = TRUE) * 24 * 3600,
             linetype = "dashed") +
  geom_bar(stat = 'identity',
           aes(fill = VIP > 0.8))

VIP_plot

VIP_plot <- VIP_plot + 
  facet_wrap(vars(Type),
             scales = "free",
             strip.position = "left",
             labeller = 
               labeller(Type = as_labeller(
                 c(Chill = "VIP for chill",
                   Heat = "VIP for heat")))) +
  scale_y_continuous(
    limits = c(0,
               max(plscf$Chill_Portions$GDH$PLS_summary$VIP))) +
  ggtitle("Variable Importance in the Projection (VIP) scores") +
  theme_bw(base_size = 15) + 
  theme(strip.background = element_blank(),
        strip.placement = "outside",
        strip.text.y = element_text(size = 12),
        plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank()
        )
  
VIP_plot

VIP_plot <- VIP_plot +
  scale_fill_manual(name = "VIP", 
                    labels = c("<0.8", ">0.8"), 
                    values = c("FALSE" = "grey",
                               "TRUE" = "blue")) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())

VIP_plot

coeff_plot <- ggplot(PLS_gg,
                     aes(x = Date,
                         y = Coef)) +
  annotate("rect",
           xmin = chill_start_date,
           xmax = chill_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "blue") +
  annotate("rect",
           xmin = heat_start_date,
           xmax = heat_end_date,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "red") +
  annotate("rect",
           xmin = ISOdate(2001,
                          12,
                          31) +
             min(plscf$pheno$pheno,
                 na.rm=TRUE) * 24 * 3600,
           xmax = ISOdate(2001,
                          12,
                          31) +
             max(plscf$pheno$pheno,
                 na.rm = TRUE) * 24 * 3600,
           ymin = -Inf,
           ymax = Inf,
           alpha = .1,
           fill = "black") +
  geom_vline(xintercept = ISOdate(2001,
                                  12,
                                  31) +
               median(plscf$pheno$pheno,
                      na.rm = TRUE) * 24 * 3600,
             linetype = "dashed") +
  geom_bar(stat = 'identity',
           aes(fill = VIP_Coeff))

coeff_plot

coeff_plot <- coeff_plot +
  facet_wrap(vars(Type),
             scales = "free",
             strip.position = "left",
             labeller =
               labeller(
                 Type = as_labeller(
                   c(Chill = "MC for chill",
                     Heat = "MC for heat")))) +
  scale_y_continuous(
    limits = c(min(plscf$Chill_Portions$GDH$PLS_summary$Coef),
               max(plscf$Chill_Portions$GDH$PLS_summary$Coef))) +
  ggtitle("Model coefficients (MC)") +
  theme_bw(base_size = 15) + 
  theme(strip.background = element_blank(),
        strip.placement = "outside",
        strip.text.y = element_text(size = 12),
        plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank()
        )
  
coeff_plot 

coeff_plot <- coeff_plot +  
  scale_fill_manual(name="Effect direction", 
                    labels = c("Advancing",
                               "Unimportant",
                               "Delaying"), 
                    values = c("-1" = "red",
                               "0" = "grey",
                               "1" = "dark green")) +
  ylab("PLS coefficient") +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())

coeff_plot

library(patchwork)

plot<- (VIP_plot +
          coeff_plot +
          temp_plot +
          plot_layout(ncol = 1,
            guides = "collect")
        ) & theme(legend.position = "right",
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 10),
                  axis.title.x = element_blank())

plot


plot_PLS_chill_force <- function(plscf,
                                 chill_metric = "Chill_Portions",
                                 heat_metric = "GDH",
                                 chill_label = "CP",
                                 heat_label = "GDH",
                                 chill_phase = c(-48, 62),
                                 heat_phase = c(-5, 105.5))
{
  PLS_gg <- plscf[[chill_metric]][[heat_metric]]$PLS_summary %>%
    mutate(Month = trunc(Date/100),
           Day = Date - Month * 100,
           Date = ISOdate(2002,
                          Month,
                          Day))
  
  PLS_gg[PLS_gg$JDay <= 0,"Date"]<-
    ISOdate(2001,
            PLS_gg$Month[PLS_gg$JDay <= 0],
            PLS_gg$Day[PLS_gg$JDay <= 0])
  
  PLS_gg <- PLS_gg %>%
    mutate(VIP_importance = VIP >= 0.8,
           VIP_Coeff = factor(sign(Coef) * VIP_importance))
  
  chill_start_date <- ISOdate(2001,
                              12,
                              31) + chill_phase[1] * 24 * 3600
  chill_end_date <- ISOdate(2001,
                            12,
                            31) + chill_phase[2] * 24 * 3600
  heat_start_date <- ISOdate(2001,
                             12,
                             31) + heat_phase[1] * 24 * 3600
  heat_end_date <- ISOdate(2001,
                           12,
                           31) + heat_phase[2] * 24 * 3600




  temp_plot <- ggplot(PLS_gg) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) +
               min(plscf$pheno$pheno,
                   na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) +
               max(plscf$pheno$pheno,
                   na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) +
                 median(plscf$pheno$pheno,
                        na.rm=TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev ,
                    ymax = MetricMean + MetricStdev ),
                fill = "grey") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev * (VIP_Coeff == -1),
                    ymax = MetricMean + MetricStdev * (VIP_Coeff == -1)),
                fill = "red") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev * (VIP_Coeff == 1),
                    ymax = MetricMean + MetricStdev * (VIP_Coeff == 1)),
                fill = "dark green") +
    geom_line(aes(x = Date,
                  y = MetricMean)) +
    facet_wrap(vars(Type),
               scales = "free_y",
               strip.position = "left",
               labeller = 
                 labeller(
                   Type =
                     as_labeller(c(Chill = paste0("Chill (",
                                                  chill_label,
                                                  ")"),
                                   Heat = paste0("Heat (",
                                                 heat_label,
                                                 ")"))))) +
    ggtitle("Daily chill and heat accumulation rates") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          )
  
  VIP_plot <- ggplot(PLS_gg,
                     aes(x = Date,
                         y = VIP)) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) + min(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) + max(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) + median(plscf$pheno$pheno,
                                                 na.rm = TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_bar(stat = 'identity',
             aes(fill = VIP>0.8)) +
    facet_wrap(vars(Type), 
               scales = "free",
               strip.position = "left",
               labeller = 
                 labeller(
                   Type = as_labeller(c(Chill="VIP for chill",
                                        Heat="VIP for heat")))) +
    scale_y_continuous(
      limits=c(0,
               max(plscf[[chill_metric]][[heat_metric]]$PLS_summary$VIP))) +
    ggtitle("Variable Importance in the Projection (VIP) scores") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          ) +
    scale_fill_manual(name = "VIP", 
                      labels = c("<0.8", ">0.8"), 
                      values = c("FALSE" = "grey",
                                 "TRUE" = "blue")) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  coeff_plot <- ggplot(PLS_gg,
                       aes(x = Date,
                           y = Coef)) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) + min(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) + max(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) + median(plscf$pheno$pheno,
                                                 na.rm = TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_bar(stat = 'identity',
             aes(fill = VIP_Coeff)) +
    facet_wrap(vars(Type),
               scales = "free",
               strip.position = "left",
               labeller =
                 labeller(
                   Type = as_labeller(c(Chill = "MC for chill",
                                        Heat = "MC for heat")))) +
    scale_y_continuous(
      limits = c(min(plscf[[chill_metric]][[heat_metric]]$PLS_summary$Coef),
                 max(plscf[[chill_metric]][[heat_metric]]$PLS_summary$Coef))) +
    ggtitle("Model coefficients (MC)") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          ) +
    scale_fill_manual(name="Effect direction", 
                      labels = c("Advancing",
                                 "Unimportant",
                                 "Delaying"), 
                      values = c("-1" = "red",
                                 "0" = "grey",
                                 "1" = "dark green")) +
    ylab("PLS coefficient") +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
   library(patchwork)
  
  plot <- (VIP_plot +
             coeff_plot +
             temp_plot +
             plot_layout(ncol=1,
                         guides = "collect")
           ) & theme(legend.position = "right",
                     legend.text = element_text(size = 8),
                     legend.title = element_text(size = 10),
                     axis.title.x = element_blank())

plot

}

plot_PLS_chill_force(plscf)
```



3. Plot results for all three analyses, including shaded plot areas for the chilling and forcing periods you estimated. 


```{r}

daychill <- daily_chill(hourtemps = temps_hourly,
                        running_mean = 11,
                        models = list(Chilling_Hours = Chilling_Hours,
                                      Utah_Chill_Units = Utah_Model,
                                      Chill_Portions = Dynamic_Model,
                                      GDH = GDH)
                        )

plscf <- PLS_chill_force(daily_chill_obj = daychill,
                         bio_data_frame = Roter_Boskoop,
                         split_month = 6,
                         chill_models = c("Chilling_Hours",
                                          "Utah_Chill_Units",
                                          "Chill_Portions"),
                       heat_models = c("GDH"))

plot_PLS_chill_force(plscf,
                     chill_metric = "Chilling_Hours",
                     heat_metric = "GDH",
                     chill_label = "CH",
                     heat_label = "GDH",
                     chill_phase = c(0,0),
                     heat_phase = c(0,0))

plot_PLS_chill_force(plscf,
                     chill_metric = "Utah_Chill_Units",
                     heat_metric = "GDH",
                     chill_label = "CU",
                     heat_label = "GDH",
                     chill_phase = c(0,0),
                     heat_phase = c(0,0))

plot_PLS_chill_force(plscf,
                     chill_metric = "Chill_Portions",
                     heat_metric = "GDH",
                     chill_label = "CP",
                     heat_label = "GDH",
                     chill_phase = c(0,0),
                     heat_phase = c(0,0))



```



------------------------------------------------------------------------

# Chapter 24: PLS regression with agroclimatic metrics

## ***Exercises on examples of PLS regression with agroclimatic metrics***

1. Look across all the PLS results presented above. Can you detect a pattern in where chilling and forcing periods could be delineated clearly, and where this attempt failed?

PLS regression doesn't allow easy delineation of temperature response phases, especially when it comes to the chilling period. This problem didn’t really go away after replacing temperatures with agroclimatic metrics in the analysis.

PLS looks responses of a variable to variation in the input variable. This response should be monotonic (bloom date should be positively or negatively correlated with the input variables). The sign of this relationship should not change halfway through the range of the input variables.

Another prerequisite for a successful PLS regression, is that there needs to be meaningful variation in the signal variables in the first place.

2. Think about possible reasons for the success or failure of PLS analysis based on agroclimatic metrics. Write down your thoughts.

------------------------------------------------------------------------

# Chapter 25: PLS regression with agroclimatic metrics

## ***Exercises on expected PLS responsiveness***

Produce chill and heat model sensitivity plots for the location you focused on in previous exercises.



```{r}
library(chillR)
library(tidyverse)

mon <- 1 # Month
ndays <- 31 # Number of days per month
tmin <- 1
tmax <- 8
latitude <- 43 #Rochester


weather <- make_all_day_table(
            data.frame(Year = c(2001, 2001),
                       Month = c(mon, mon),
                       Day = c(1, ndays),
                       Tmin = c(0, 0),
                       Tmax = c(0, 0))) %>%
  mutate(Tmin = tmin,
         Tmax = tmax)

hourly_temps <- stack_hourly_temps(weather,
                                   latitude = latitude)

CPs <- Dynamic_Model(
     hourly_temps$hourtemps$Temp)

daily_CPs <- tail(CPs, 1) / nrow(weather)

daily_CPs #chill portions




latitude <- 43.1

month_range <- c(10, 11, 12, 1, 2, 3)

Tmins <- c(-20:20) # calculate sensitivity for expected temps in winter
Tmaxs <- c(-15:30) # range

mins <- NA
maxs <- NA
CP <- NA
month <- NA
temp_model <- Dynamic_Model # model for temp


for(mon in month_range)
    {days_month <- as.numeric( # number of days in a month
      difftime( ISOdate(2002, # time difference of 31 days
                        mon+1,
                        1),
                ISOdate(2002,
                        mon,
                        1)))

    if(mon == 12) days_month <- 31

    weather <- make_all_day_table(
                data.frame(Year = c(2001, 2001),
                           Month = c(mon, mon),
                           Day = c(1, days_month),
                           Tmin = c(0, 0),
                           Tmax = c(0, 0)))

    for(tmin in Tmins)
      for(tmax in Tmaxs)
        if(tmax >= tmin)
          {
          hourtemps <- weather %>%
            mutate(Tmin = tmin,
                   Tmax = tmax) %>%
            stack_hourly_temps(latitude = latitude) %>%
            pluck("hourtemps", "Temp")

          CP <- c(CP,
                  tail(do.call(temp_model,
                          list(hourtemps)), 1) /
                    days_month)
          mins <- c(mins, tmin)
          maxs <- c(maxs, tmax)
          month <- c(month, mon)
        }
}

results <- data.frame(Month = month,
                      Tmin = mins,
                      Tmax = maxs,
                      CP)

results <- results[!is.na(results$Month),
                   ]


write.csv(results,
          "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/model_sensitivity_development.csv",
          row.names = FALSE)

head(results)

results <- read.csv("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/model_sensitivity_development.csv")



library(ggplot2)
library(colorRamps)

results$Month_names <- factor(results$Month,
                              levels = month_range,# october to march
                              labels = month.name[month_range])  

DM_sensitivity <- ggplot(results, # heat map
                         aes(x = Tmin,
                             y = Tmax,
                             fill = CP)) +
  geom_tile() +
  scale_fill_gradientn(colours = alpha(matlab.like(15),
                                       alpha = .5),
                       name = "Chill/day (CP)") +
  ylim(min(results$Tmax),
       max(results$Tmax)) +
  ylim(min(results$Tmin),
       max(results$Tmin))

DM_sensitivity

DM_sensitivity <- DM_sensitivity +
  facet_wrap(vars(Month_names)) + # facet_wraps separates them by months
  ylim(min(results$Tmax),
       max(results$Tmax)) +
  ylim(min(results$Tmin),
       max(results$Tmin))

DM_sensitivity # nothing happens at -20 temp, at temp below freezing -10, we see some reactions,  

temperatures <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv") %>%
  filter(Month %in% month_range) %>%
  mutate(Month_names =
           factor(Month,
                  levels = c(10, 11, 12, 1, 2, 3),
                  labels = c("October", "November", "December",
                             "January", "February", "March"))) #rename months

temperatures[which(temperatures$Tmax < temperatures$Tmin),
             c("Tmax", "Tmin")] <- NA

DM_sensitivity +
  geom_point(data = temperatures,
             aes(x = Tmin,
                 y = Tmax,
                 fill = NULL,
                 color = "Temperature"),
             size = 0.2) +
  facet_wrap(vars(Month_names)) +
  scale_color_manual(values = "black",
                     labels = "Daily temperature \nextremes (°C)",
                     name = "Observed at site" ) +
  guides(fill = guide_colorbar(order = 1),
         color = guide_legend(order = 2)) +
  ylab("Tmax (°C)") +
  xlab("Tmin (°C)") + 
  theme_bw(base_size = 15) # Model response in relationship to temps observed in Rochester

Chill_model_sensitivity<- # creating a function for other locations
  function(latitude,
           temp_models = list(Dynamic_Model = Dynamic_Model,
                              GDH = GDH),
           month_range = c(10, 11, 12, 1, 2, 3),
           Tmins = c(-10:20),
           Tmaxs = c(-5:30))
  {
  mins <- NA
  maxs <- NA
  metrics <- as.list(rep(NA,
                         length(temp_models)))
  names(metrics) <- names(temp_models)
  month <- NA
 
  for(mon in month_range)
    {
    days_month <-
      as.numeric(difftime( ISOdate(2002,
                                   mon+1,
                                   1),
                           ISOdate(2002,
                                   mon,
                                   1) ))
    if(mon == 12) days_month <- 31
    weather <- 
      make_all_day_table(data.frame(Year = c(2001, 2001),
                                    Month = c(mon, mon),
                                    Day = c(1, days_month),
                                    Tmin = c(0, 0),
                                    Tmax = c(0, 0)))

    
    for(tmin in Tmins)
      for(tmax in Tmaxs)
        if(tmax >= tmin)
          {
          hourtemps <- weather %>%
            mutate(Tmin = tmin,
                   Tmax = tmax) %>%
            stack_hourly_temps(
              latitude = latitude) %>%
            pluck("hourtemps",
                  "Temp")
          
          for(tm in 1:length(temp_models))
            metrics[[tm]] <- 
              c(metrics[[tm]],
                tail(do.call(temp_models[[tm]],
                        list(hourtemps)),1)/
                  days_month)
          
          mins <- c(mins, tmin)
          maxs <- c(maxs, tmax)
          month <- c(month, mon)
        }
    }
  results <- cbind(data.frame(Month = month,
                              Tmin = mins,
                              Tmax = maxs),
                   as.data.frame(metrics))
  
  results <- results[!is.na(results$Month),]
}


Chill_sensitivity_temps <-
  function(chill_model_sensitivity_table,
           temperatures,
           temp_model,
           month_range = c(10, 11, 12, 1, 2, 3),
           Tmins = c(-10:20),
           Tmaxs = c(-5:30),
           legend_label = "Chill/day (CP)")
{
  library(ggplot2)
  library(colorRamps)

  cmst <- chill_model_sensitivity_table
  cmst <- cmst[which(cmst$Month %in% month_range),]
  cmst$Month_names <- factor(cmst$Month,
                             levels = month_range,
                             labels = month.name[month_range])  
  
  DM_sensitivity<-
    ggplot(cmst,
           aes_string(x = "Tmin",
                      y = "Tmax",
                      fill = temp_model)) +
    geom_tile() +
    scale_fill_gradientn(colours = alpha(matlab.like(15),
                                         alpha = .5),
                         name = legend_label) +
    xlim(Tmins[1],
         Tmins[length(Tmins)]) +
    ylim(Tmaxs[1],
         Tmaxs[length(Tmaxs)])
  
  temperatures<-
    temperatures[which(temperatures$Month %in% month_range),]
  
  temperatures[which(temperatures$Tmax < temperatures$Tmin),
               c("Tmax", 
                 "Tmin")] <- NA
  
  temperatures$Month_names <-
    factor(temperatures$Month,
           levels = month_range,
           labels = month.name[month_range])  
  
  DM_sensitivity +
    geom_point(data = temperatures,
               aes(x = Tmin,
                   y = Tmax,
                   fill = NULL,
                   color = "Temperature"),
               size = 0.2) +
    facet_wrap(vars(Month_names)) +
    scale_color_manual(values = "black",
                       labels = "Daily temperature \nextremes (°C)",
                       name = "Observed at site" ) +
    guides(fill = guide_colorbar(order = 1),
           color = guide_legend(order = 2)) +
    ylab("Tmax (°C)") +
    xlab("Tmin (°C)") + 
    theme_bw(base_size = 15)

}
  


Model_sensitivities_CNY <- # Rochester, New York
  Chill_model_sensitivity(latitude = 43,
                          temp_models = list(Dynamic_Model = Dynamic_Model,
                                             GDH = GDH),
                          month_range = c(10:12, 1:5))

write.csv(Model_sensitivities_CNY,
          "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Model_sensitivities_CNY.csv",
          
          row.names = FALSE)


Model_sensitivities_CNY <- read.csv("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Model_sensitivities_CNY.csv")

Rochester_weather <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_weather.csv")

Chill_sensitivity_temps(Model_sensitivities_CNY,
                        Rochester_weather,
                        temp_model = "Dynamic_Model",
                        month_range = c(10, 11, 12, 1, 2, 3),
                        legend_label = "Chill per day \n(Chill Portions)") +
  ggtitle("Chill model sensitivity at Rochester, New York")
```

```{r}
#
Chill_sensitivity_temps(Model_sensitivities_CNY,
                        Rochester_weather,
                        temp_model = "GDH",
                        month_range = c(12, 1:5),
                        legend_label = "Heat per day \n(GDH)") +
  ggtitle("Heat model sensitivity at Rochester, New York")


```


------------------------------------------------------------------------

# Chapter 26: Evaluating PLS outputs

## ***Exercises on expected PLS results***

1. Reproduce the analysis for the ‘Roter Boskoop’ dataset.



```{r, eval = FALSE}
library(chillR)
library(magrittr)
library(tidyverse)

Roter_first <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Roter_Boskoop_bloom_1958_2019.csv.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, 
         JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay)

temps <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv")

temps_hourly <- temps %>%
  stack_hourly_temps(latitude = 43.1)

daychill <- daily_chill(hourtemps = temps_hourly,
                        running_mean = 1,
                        models = list(Chilling_Hours = Chilling_Hours,
                                      Utah_Chill_Units = Utah_Model,
                                      Chill_Portions = Dynamic_Model,
                                      GDH = GDH)
                        )


plscf <- PLS_chill_force(daily_chill_obj = daychill,
                         bio_data_frame = Roter_first,
                         split_month = 6,
                         chill_models = "Chill_Portions",
                         heat_models = "GDH",
                         runn_means = 11)


library(ggplot2)
plot_PLS_chill_force <- function(plscf,
                                 chill_metric = "Chill_Portions",
                                 heat_metric = "GDH",
                                 chill_label = "CP",
                                 heat_label = "GDH",
                                 chill_phase = c(-48, 62),
                                 heat_phase = c(-5, 105.5))
{
  PLS_gg <- plscf[[chill_metric]][[heat_metric]]$PLS_summary %>%
    mutate(Month = trunc(Date/100),
           Day = Date - Month * 100,
           Date = ISOdate(2002,
                          Month,
                          Day))
  
  PLS_gg[PLS_gg$JDay <= 0,"Date"]<-
    ISOdate(2001,
            PLS_gg$Month[PLS_gg$JDay <= 0],
            PLS_gg$Day[PLS_gg$JDay <= 0])
  
  PLS_gg <- PLS_gg %>%
    mutate(VIP_importance = VIP >= 0.8,
           VIP_Coeff = factor(sign(Coef) * VIP_importance))
  
  chill_start_date <- ISOdate(2001,
                              12,
                              31) + chill_phase[1] * 24 * 3600
  chill_end_date <- ISOdate(2001,
                            12,
                            31) + chill_phase[2] * 24 * 3600
  heat_start_date <- ISOdate(2001,
                             12,
                             31) + heat_phase[1] * 24 * 3600
  heat_end_date <- ISOdate(2001,
                           12,
                           31) + heat_phase[2] * 24 * 3600




  temp_plot <- ggplot(PLS_gg) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) +
               min(plscf$pheno$pheno,
                   na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) +
               max(plscf$pheno$pheno,
                   na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) +
                 median(plscf$pheno$pheno,
                        na.rm=TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev ,
                    ymax = MetricMean + MetricStdev ),
                fill = "grey") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev * (VIP_Coeff == -1),
                    ymax = MetricMean + MetricStdev * (VIP_Coeff == -1)),
                fill = "red") +
    geom_ribbon(aes(x = Date,
                    ymin = MetricMean - MetricStdev * (VIP_Coeff == 1),
                    ymax = MetricMean + MetricStdev * (VIP_Coeff == 1)),
                fill = "dark green") +
    geom_line(aes(x = Date,
                  y = MetricMean)) +
    facet_wrap(vars(Type),
               scales = "free_y",
               strip.position = "left",
               labeller = 
                 labeller(
                   Type =
                     as_labeller(c(Chill = paste0("Chill (",
                                                  chill_label,
                                                  ")"),
                                   Heat = paste0("Heat (",
                                                 heat_label,
                                                 ")"))))) +
    ggtitle("Daily chill and heat accumulation rates") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          )
  
  VIP_plot <- ggplot(PLS_gg,
                     aes(x = Date,
                         y = VIP)) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) + min(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) + max(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) + median(plscf$pheno$pheno,
                                                 na.rm = TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_bar(stat = 'identity',
             aes(fill = VIP>0.8)) +
    facet_wrap(vars(Type), 
               scales = "free",
               strip.position = "left",
               labeller = 
                 labeller(
                   Type = as_labeller(c(Chill="VIP for chill",
                                        Heat="VIP for heat")))) +
    scale_y_continuous(
      limits = c(0,
                 max(plscf[[chill_metric]][[heat_metric]]$PLS_summary$VIP))) +
    ggtitle("Variable Importance in the Projection (VIP) scores") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          ) +
    scale_fill_manual(name = "VIP", 
                      labels = c("<0.8", ">0.8"), 
                      values = c("FALSE" = "grey",
                                 "TRUE" = "blue")) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  coeff_plot <- ggplot(PLS_gg,
                       aes(x = Date,
                           y = Coef)) +
    annotate("rect",
             xmin = chill_start_date,
             xmax = chill_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "blue") +
    annotate("rect",
             xmin = heat_start_date,
             xmax = heat_end_date,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "red") +
    annotate("rect",
             xmin = ISOdate(2001,
                            12,
                            31) + min(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             xmax = ISOdate(2001,
                            12,
                            31) + max(plscf$pheno$pheno,
                                      na.rm = TRUE) * 24 * 3600,
             ymin = -Inf,
             ymax = Inf,
             alpha = .1,
             fill = "black") +
    geom_vline(xintercept = ISOdate(2001,
                                    12,
                                    31) + median(plscf$pheno$pheno,
                                                 na.rm = TRUE) * 24 * 3600,
               linetype = "dashed") +
    geom_bar(stat = 'identity',
             aes(fill = VIP_Coeff)) +
    facet_wrap(vars(Type),
               scales = "free",
               strip.position = "left",
               labeller =
                 labeller(
                   Type = as_labeller(c(Chill = "MC for chill",
                                        Heat = "MC for heat")))) +
    scale_y_continuous(
      limits = c(min(plscf[[chill_metric]][[heat_metric]]$PLS_summary$Coef),
                 max(plscf[[chill_metric]][[heat_metric]]$PLS_summary$Coef))) +
    ggtitle("Model coefficients (MC)") +
    theme_bw(base_size = 15) + 
    theme(strip.background = element_blank(),
          strip.placement = "outside",
          strip.text.y = element_text(size = 12),
          plot.title = element_text(hjust = 0.5),
          axis.title.y = element_blank()
          ) +
    scale_fill_manual(name = "Effect direction", 
                      labels = c("Advancing",
                                 "Unimportant",
                                 "Delaying"), 
                      values = c("-1" = "red",
                                 "0" = "grey",
                                 "1" = "dark green")) +
    ylab("PLS coefficient") +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  library(patchwork)
  
  plot <- (VIP_plot +
             coeff_plot +
             temp_plot +
             plot_layout(ncol = 1,
                         guides = "collect")
           ) & theme(legend.position = "right",
                     legend.text = element_text(size = 8),
                     legend.title = element_text(size = 10),
                     axis.title.x = element_blank())

plot

}




plot_PLS_chill_force(plscf,
                     chill_metric = "Chill_Portions",
                     heat_metric = "GDH",
                     chill_label = "CP",
                     heat_label = "GDH",
                     chill_phase = c(-48, 62),
                     heat_phase = c(-5, 105.5))
```

```{r, eval = FALSE}
chill_phase <- c(317, 62)
heat_phase <- c(360, 105.5)

chill <- tempResponse(hourtemps = temps_hourly,
                      Start_JDay = chill_phase[1],
                      End_JDay = chill_phase[2],
                      models = list(Chill_Portions = Dynamic_Model),
                      misstolerance = 10)

heat <- tempResponse(hourtemps = temps_hourly,
                     Start_JDay = heat_phase[1],
                     End_JDay = heat_phase[2],
                     models = list(GDH = GDH))


ggplot(data = chill,
       aes(x = Chill_Portions)) +
  geom_histogram() +
  ggtitle("Chill accumulation during endodormancy (Chill Portions)") +
  xlab("Chill accumulation (Chill Portions)") +
  ylab("Frequency between 1958 and 2019") +
  theme_bw(base_size = 12)

ggplot(data = heat,
       aes(x = GDH)) +
  geom_histogram() +
  ggtitle("Heat accumulation during ecodormancy (GDH)") +
  xlab("Heat accumulation (Growing Degree Hours)") +
  ylab("Frequency between 1958 and 2019") +
  theme_bw(base_size = 12)


chill_requirement <- mean(chill$Chill_Portions)
chill_req_error <- sd(chill$Chill_Portions)

chill_nonpara <- quantile(chill$Chill_Portions,
                          c(0.05, 0.5, 0.95))

heat_requirement <- mean(heat$GDH)
heat_req_error <- sd(heat$GDH)

heat_nonpara <- quantile(heat$GDH,
                          c(0.05, 0.5, 0.95))

chill_phase <- c(317, 62)
heat_phase <- c(360, 106)


mpt <- make_pheno_trend_plot(weather_data_frame = temps,
                             pheno = Roter_first,
                             Start_JDay_chill = chill_phase[1],
                             End_JDay_chill = chill_phase[2],
                             Start_JDay_heat = heat_phase[1],
                             End_JDay_heat = heat_phase[2],
                             outpath = "data/",
                             file_name = "pheno_trend_plot",
                             plot_title =  "Impacts of chilling and forcing temperatures on pear phenology",
                             image_type = "png",
                             colorscheme = "normal")


mean_temp_period <- function(
    temps,
    start_JDay,
    end_JDay,
    end_season = end_JDay)
{ temps_JDay <- make_JDay(temps) %>%
  mutate(Season =Year)
  
  if(start_JDay > end_season)
    temps_JDay$Season[which(temps_JDay$JDay >= start_JDay)]<-
        temps_JDay$Year[which(temps_JDay$JDay >= start_JDay)]+1
  
  if(start_JDay > end_season)
    sub_temps <- subset(temps_JDay,
                        JDay <= end_JDay | JDay >= start_JDay)
  
  if(start_JDay <= end_JDay)
    sub_temps <- subset(temps_JDay,
                        JDay <= end_JDay & JDay >= start_JDay)
  
  mean_temps <- aggregate(sub_temps[, c("Tmin", "Tmax")],
                          by = list(sub_temps$Season),
                          FUN = function(x) mean(x,
                                                 na.rm=TRUE))
  
  mean_temps[, "n_days"] <- aggregate(sub_temps[, "Tmin"],
                                      by = list(sub_temps$Season),
                                      FUN = length)[,2]
  
  mean_temps[, "Tmean"] <- (mean_temps$Tmin + mean_temps$Tmax) / 2
  mean_temps <- mean_temps[, c(1, 4, 2, 3, 5)]
  colnames(mean_temps)[1] <- "End_year"
  
  return(mean_temps)
}

mean_temp_chill <- mean_temp_period(temps = temps,
                                    start_JDay = chill_phase[1],
                                    end_JDay = chill_phase[2],
                                    end_season = 60)

mean_temp_heat <- mean_temp_period(temps = temps,
                                   start_JDay = heat_phase[1],
                                   end_JDay = heat_phase[2],
                                   end_season = 60)


mean_temp_chill <- 
  mean_temp_chill[which(mean_temp_chill$n_days >=
                          max(mean_temp_chill$n_days)-1),]
mean_temp_heat <-
  mean_temp_heat[which(mean_temp_heat$n_days >=
                         max(mean_temp_heat$n_days)-1),]

mean_chill <- mean_temp_chill[, c("End_year",
                                  "Tmean")]
colnames(mean_chill)[2] <- "Tmean_chill"

mean_heat <- mean_temp_heat[,c("End_year",
                               "Tmean")]
colnames(mean_heat)[2] <- "Tmean_heat"

phase_Tmeans <- merge(mean_chill,
                      mean_heat, 
                      by = "End_year")


pheno <- Roter_first
colnames(pheno)[1] <- "End_year"

Tmeans_pheno <- merge(phase_Tmeans,
                      pheno,
                      by = "End_year")


head(Tmeans_pheno)



library(fields)
k <- Krig(x = as.matrix(
                Tmeans_pheno[,
                             c("Tmean_chill",
                               "Tmean_heat")]),
          Y = Tmeans_pheno$pheno)

pred <- predictSurface(k)
colnames(pred$z) <- pred$y
rownames(pred$z) <- pred$x

library(reshape2)
melted <- melt(pred$z)
  
library(metR)
library(colorRamps)
  
colnames(melted) <- c("Tmean_chill",
                      "Tmean_heat",
                      "value")


ggplot(melted,
       aes(x = Tmean_chill,
           y = Tmean_heat,
           z = value)) +
  geom_contour_fill(bins = 100) +
  scale_fill_gradientn(colours = alpha(matlab.like(15)),
                       name = "Bloom date \n(day of the year)") +
  geom_contour(col = "black")  +
  geom_point(data = Tmeans_pheno,
             aes(x = Tmean_chill,
                 y = Tmean_heat,
                 z = NULL),
             size = 0.7) +
  geom_text_contour(stroke = 0.2) +
  ylab(expression(paste("Forcing phase ", 
                        T[mean],
                        " (",
                        degree,
                        "C)"))) +
  xlab(expression(paste("Chilling phase ",
                        T[mean],
                        " (",
                        degree,
                        "C)")))  +
  theme_bw(base_size = 15)
    





pheno_trend_ggplot <- function(temps,
                               pheno,
                               chill_phase,
                               heat_phase,
                               phenology_stage = "Bloom")
{
  library(fields)
  library(reshape2)
  library(metR)
  library(ggplot2)
  library(colorRamps)
  
  mean_temp_period <- function(temps,
                               start_JDay,
                               end_JDay, 
                               end_season = end_JDay)
    { temps_JDay <- make_JDay(temps) %>%
      mutate(Season = Year)

    if(start_JDay > end_season)
      temps_JDay$Season[which(temps_JDay$JDay >= start_JDay)] <-
        temps_JDay$Year[which(temps_JDay$JDay >= start_JDay)]+1
    
    if(start_JDay > end_season)
      sub_temps <- subset(temps_JDay,
                          JDay <= end_JDay | JDay >= start_JDay)
    
    if(start_JDay <= end_JDay)
      sub_temps <- subset(temps_JDay,
                          JDay <= end_JDay & JDay >= start_JDay)
    
    mean_temps <- aggregate(sub_temps[,
                                      c("Tmin",
                                        "Tmax")],
                            by = list(sub_temps$Season),
                            FUN = function(x) mean(x,
                                                   na.rm = TRUE))
    mean_temps[, "n_days"] <- aggregate(sub_temps[,
                                                  "Tmin"],
                                        by = list(sub_temps$Season),
                                        FUN = length)[,2]
    
    mean_temps[,"Tmean"] <- (mean_temps$Tmin + mean_temps$Tmax) / 2
    mean_temps <- mean_temps[, c(1, 4, 2, 3, 5)]
    colnames(mean_temps)[1] <- "End_year"
    return(mean_temps)
    }
  
  mean_temp_chill <- mean_temp_period(temps = temps,
                                      start_JDay = chill_phase[1],
                                      end_JDay = chill_phase[2],
                                      end_season = heat_phase[2])
  
  mean_temp_heat <- mean_temp_period(temps = temps,
                                     start_JDay = heat_phase[1],
                                     end_JDay = heat_phase[2],
                                     end_season = heat_phase[2])
  
  mean_temp_chill <-
    mean_temp_chill[which(mean_temp_chill$n_days >= 
                            max(mean_temp_chill$n_days)-1),]
  mean_temp_heat <-
    mean_temp_heat[which(mean_temp_heat$n_days >= 
                           max(mean_temp_heat$n_days)-1),]
  mean_chill <- mean_temp_chill[, c("End_year",
                                    "Tmean")]
  colnames(mean_chill)[2] <- "Tmean_chill"
  mean_heat<-mean_temp_heat[,c("End_year",
                               "Tmean")]
  colnames(mean_heat)[2] <- "Tmean_heat"
  phase_Tmeans <- merge(mean_chill,
                        mean_heat,
                        by = "End_year")
  
  colnames(pheno) <- c("End_year",
                       "pheno")
  Tmeans_pheno <- merge(phase_Tmeans,
                        pheno, 
                        by="End_year")
  
  # Kriging interpolation
  k <- Krig(x = as.matrix(Tmeans_pheno[,c("Tmean_chill",
                                          "Tmean_heat")]),
            Y = Tmeans_pheno$pheno)
  pred <- predictSurface(k)
  colnames(pred$z) <- pred$y
  rownames(pred$z) <- pred$x
  melted <- melt(pred$z)
  colnames(melted) <- c("Tmean_chill",
                        "Tmean_heat",
                        "value")
  
  ggplot(melted,
         aes(x = Tmean_chill,
             y = Tmean_heat,
             z = value)) +
    geom_contour_fill(bins = 60) +
    scale_fill_gradientn(colours = alpha(matlab.like(15)),
                         name = paste(phenology_stage,
                                      "date \n(day of the year)")) +
    geom_contour(col = "black") +
    geom_text_contour(stroke = 0.2) +
    geom_point(data = Tmeans_pheno,
               aes(x = Tmean_chill,
                   y = Tmean_heat,
                   z = NULL),
               size = 0.7)  +
    ylab(expression(paste("Forcing phase ",
                          T[mean],
                          " (",
                          degree,
                          "C)"))) +
    xlab(expression(paste("Chilling phase ",
                          T[mean],
                          " (",
                          degree,
                          "C)"))) +
    theme_bw(base_size = 15)
}


chill_phase <- c(317, 62)
heat_phase <- c(360, 105.5)

pheno_trend_ggplot(temps = temps,
                   pheno = Roter_first,
                   chill_phase = chill_phase,
                   heat_phase = heat_phase,
                   phenology_stage = "Bloom")

# Applying to california 
# Cali_temps <- read_tab("data/Davis_weather.csv")
# Walnut_pheno <- read_tab("data/Davis_Payne_leaf_out.csv") %>%
#   mutate(Year = as.numeric(substr(Leaf.date,7,8)),
#          Year = Year+(19+(Year<25))*100,
#          Month = as.numeric(substr(Leaf.date,4,5)),
#          Day = as.numeric(substr(Leaf.date,1,2))) %>%
#   make_JDay() %>%
#   select(Year, JDay)
# 
# colnames(Walnut_pheno) <- c("Year",
#                             "pheno")
# 
# Cali_temps_hourly <- stack_hourly_temps(Cali_temps,
#                                         latitude = 38.5)
# 
# Cali_daychill <- daily_chill(hourtemps = Cali_temps_hourly,
#                              running_mean = 1,
#                              models = list(Chilling_Hours = Chilling_Hours,
#                                            Utah_Chill_Units = Utah_Model,
#                                            Chill_Portions = Dynamic_Model,
#                                            GDH = GDH)
#     )
# 
# 
# plscf <- PLS_chill_force(daily_chill_obj = Cali_daychill,
#                          bio_data_frame = Walnut_pheno,
#                          split_month = 6,
#                          chill_models = "Chill_Portions",
#                          heat_models = "GDH",
#                          runn_means = 11)
# 
# plot_PLS_chill_force(plscf,
#                      chill_metric = "Chill_Portions",
#                      heat_metric = "GDH",
#                      chill_label = "CP",
#                      heat_label = "GDH",
#                      chill_phase = c(-56, 5),
#                      heat_phase = c(19, 77))
# 
# pheno_trend_ggplot(temps = Cali_temps,
#                    pheno = Walnut_pheno,
#                    chill_phase = c(309, 5),
#                    heat_phase = c(19, 77),
#                    phenology_stage = "Leaf emergence")
# 

```




2.We’ve looked at data from a number of locations so far. How would you expect this surface plot to look like in Beijing? And how should it look in Tunisia?

------------------------------------------------------------------------

# Chapter 27: The relative importance of chill and heat

## ***Exercises on the relative importance of chill and heat***

Describe the temperature response hypothesis outlined in this chapter.

The temperature response hypothesis explains how the phenology of temperate trees in cold-winter climates responds to temperature variations during the chilling and forcing periods. During the ecodormancy phase, when buds are sensitive to heat, spring phenology is primarily influenced by forcing temperatures, as chill accumulation in such climates is usually high, and winter conditions are favorable for chilling. This stability makes it challenging to define the chilling period in these regions.

As endodormancy temperatures rise, temperature conditions during chill accumulation begin to influence phenology, introducing a delaying effect. This transition is marked by increasing interaction between chill and forcing temperatures, depicted as upward-bending contour lines in the hypothesis framework. With further warming, chilling temperatures dominate, eventually causing stagnation or delays in budbreak, instead of advancing phenology.

------------------------------------------------------------------------

# Chapter 29: Making valid tree phenology models

## ***Exercises on making valid tree phenology models***


1. Explain the difference between output validation and process validation.

Output validation assesses a model's predictive accuracy, while process validation ensures the model's internal logic is scientifically sound and reflective of real-world processes. For instance, output validation relies on performance metrics like Root Mean Square Error (RMSE) or Model Efficiency to quantify accuracy while requires domain knowledge about the processes to evaluate how well the model represents them. Both are important, but process validation provides deeper confidence in the model's applicability beyond specific datasets.

2. Explain what a validity domain is and why it is important to consider this whenever we want to use our model to forecast something.This is the range of conditions that the model is capable of making reliable predictions for. 

Validity domain ensures that models are applied within their appropriate scope, enhancing their reliability and relevance. In application,  model performance to be validated under conditions that resemble those predicted. 

3. What is validation for purpose?

Validation for purpose is the process of assessing whether a model is capable of achieving its intended objective in a specific context. It involves reflecting on the model's goals and evaluating if it can realistically and reliably deliver the required predictions under the conditions of interest. This approach considers the model's assumptions, structure, and data inputs to determine its applicability for a given task.



4. How can we ensure that our model is suitable for the predictions we want to make?

We must verify that the predictions we wish to make come inside the model's validity domain, meaning that the requirements for making those predictions closely match the set of requirements that the model is predicated on, in order to make sure our model is appropriate for those predictions.  Additionally, there are instances in which model predictions may remain accurate even when they are outside the model's validity domain.  The model can still be considered appropriate in certain situations, but it needs to be strongly justified.

 


------------------------------------------------------------------------

# Chapter 30: The Phenoflex Model

## ***Exercises on making valid tree phenology models***

1. Parameterize the PhenoFlex model for `Roter Boskoop’ apples.


```{r}
library(chillR)
library(ggplot2)
library(tidyverse)

CKA_weather <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv")
hourtemps <- stack_hourly_temps(CKA_weather, 
                                latitude = 50.6)

yc <- 40 # chilling requirement
zc <- 190 # heating requirement

iSeason <- genSeason(hourtemps,
                     mrange = c(8, 6), # month range
                     years = c(2009))

season_data <- hourtemps$hourtemps[iSeason[[1]],]

res <- PhenoFlex(temp = season_data$Temp,
                 times = c(1: length(season_data$Temp)),
                 zc = zc,
                 stopatzc = TRUE,
                 yc = yc,
                 basic_output = FALSE)

DBreakDay <- res$bloomindex
seasontemps <- hourtemps$hourtemps[iSeason[[1]],]
seasontemps[,"x"] <- res$x
seasontemps[,"y"] <- res$y
seasontemps[,"z"] <- res$z
seasontemps <- add_date(seasontemps)

CR_full <- seasontemps$Date[which(seasontemps$y >= yc)[1]] # the date where chilling requirement is broken
Bloom <- seasontemps$Date[which(seasontemps$z >= zc)[1]]

chillplot <- ggplot(data = seasontemps[1:DBreakDay,],
                    aes(x = Date,
                        y = y)) +
  geom_line(col = "blue",
            lwd = 1.5) +
  theme_bw(base_size = 20) +
  geom_hline(yintercept = yc,
             lty = 2,
             col = "blue",
             lwd = 1.2) +
  geom_vline(xintercept = CR_full,
             lty = 3,
             col = "blue",
             lwd = 1.2) +
  ylab("Chill accumulation (y)") +
  labs(title = "Chilling") +
  annotate("text",
           label = "Chill req. (yc)", 
           x = ISOdate(2008,10,01),
           y = yc*1.1,
           col = "blue",
           size = 5)

heatplot <- ggplot(data = seasontemps[1:DBreakDay,],
                   aes(x = Date,
                       y = z)) +
  geom_line(col = "red",
            lwd = 1.5) +
  theme_bw(base_size = 20) +
  scale_y_continuous(position = "right") +
  geom_hline(yintercept = zc,
             lty = 2,
             col = "red",
             lwd = 1.2) +
  geom_vline(xintercept = CR_full,
             lty = 3,
             col = "blue",
             lwd = 1.2) +
  geom_vline(xintercept = Bloom,
             lty = 3,
             col = "red",
             lwd = 1.2) +
  ylab("Heat accumulation (z)") +
  labs(title = "Forcing") +
  annotate("text",
           label = "Heat req. (zc)", 
           x = ISOdate(2008,10,01),
           y = zc*0.95,
           col = "red",
           size = 5)


library(patchwork)
chillplot + heatplot


yc <- 40
zc <- 190
seasons <- 1959:2019

iSeason <- genSeason(hourtemps,
                     mrange = c(8, 6),
                     years = seasons)

for (sea in 1:length(seasons))
{season_data <- hourtemps$hourtemps[iSeason[[sea]], ]
 res <- PhenoFlex(temp = season_data$Temp,
                  times = c(1: length(season_data$Temp)),
                  zc = zc,
                  stopatzc = TRUE,
                  yc = yc,
                  basic_output = FALSE)
 if(sea == 1)
    results <- season_data$DATE[res$bloomindex] else
      results <- c(results,
                   season_data$DATE[res$bloomindex])}

predictions <- data.frame(Season = seasons,
                          Prediction = results)
predictions$Prediction <-
  ISOdate(2001,
          substr(predictions$Prediction, 4, 5),
          substr(predictions$Prediction, 1, 2))

ggplot(data = predictions,
       aes(x = Season,
           y = Prediction)) +
  geom_smooth() +
  geom_point() +
  ylab("Predicted bloom date") +
  theme_bw(base_size = 15)


Roter_first <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Roter_Boskoop_bloom_1958_2019.csv.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay)

hourtemps <- 
  read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/TMaxTMin1958-2019_patched.csv") %>%
  stack_hourly_temps(latitude = 50.6)


# here's the order of the parameters (from the helpfile of the
# PhenoFlex_GDHwrapper function)
#          yc,  zc,  s1, Tu,    E0,      E1,     A0,         A1,   Tf, Tc, Tb,  slope

par <-   c(40, 190, 0.5, 25, 3372.8,  9900.3, 6319.5,
           5.939917e13,  4, 36,  4,  1.60)
upper <- c(41, 200, 1.0, 30, 4000.0, 10000.0, 7000.0,  
           6.e13, 10, 40, 10, 50.00)
lower <- c(38, 180, 0.1, 0 , 3000.0,  9000.0, 6000.0,   
           5.e13,  0,  0,  0,  0.05)

SeasonList <- genSeasonList(hourtemps$hourtemps,
                            mrange = c(8, 6),
                            years = c(1959:2018))

Fit_res <- 
  phenologyFitter(par.guess = par, 
                  modelfn = PhenoFlex_GDHwrapper,
                  bloomJDays = Roter_first$pheno[which(Roter_first$Year > 1958)],
                  SeasonList = SeasonList,
                  lower = lower,
                           upper = upper,
                           control = list(smooth = FALSE,
                                          verbose = FALSE, 
                                          maxit = 1000,
                                          nb.stop.improvement = 5))

Roter_par <- Fit_res$par

write.csv(Roter_par,
          "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/PhenoFlex_parameters_Roter_Boskoop.csv")

kable(head(Roter_par)) %>%
  kable_styling("striped", position = "left", font_size = 10)
```


2. Produce plots of predicted vs. observed bloom dates and distribution of prediction errors.



```{r}
library(chillR)
library(ggplot2)
library(tidyverse)

Roter_par <-
  read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/PhenoFlex_parameters_Roter_Boskoop.csv")[,2]

SeasonList <- genSeasonList(hourtemps$hourtemps,
                            mrange = c(8, 6),
                            years = c(1959:2018))

Roter_PhenoFlex_predictions <- Roter_first[which(Roter_first$Year > 1958),]

for(y in 1:length(Roter_PhenoFlex_predictions$Year))
   Roter_PhenoFlex_predictions$predicted[y] <-
    PhenoFlex_GDHwrapper(SeasonList[[y]],
                         Roter_par)

Roter_PhenoFlex_predictions$Error <-
  Roter_PhenoFlex_predictions$predicted -
  Roter_PhenoFlex_predictions$pheno

RMSEP(Roter_PhenoFlex_predictions$predicted,
      Roter_PhenoFlex_predictions$pheno)

mean(Roter_PhenoFlex_predictions$Error)

mean(abs(Roter_PhenoFlex_predictions$Error))

ggplot(Roter_PhenoFlex_predictions,
       aes(x = pheno,
           y = predicted)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1) +
  theme_bw(base_size = 15) +
  xlab("Observed bloom date (Day of the year)") +
  ylab("Predicted bloom date (Day of the year)") +
  ggtitle("Predicted vs. observed bloom dates")
```

```{r}
ggplot(Roter_PhenoFlex_predictions,
       aes(Error)) +
  geom_histogram() +
  ggtitle("Distribution of prediction errors") +
  theme_bw(base_size = 15)

```




3. Compute the model performance metrics RMSEP, mean error and mean absolute error.


```{r}
RMSEP <- chillR::RMSEP(Roter_PhenoFlex_predictions$predicted, Roter_PhenoFlex_predictions$pheno)

mean <- mean(Roter_PhenoFlex_predictions$Error)

abs_mean <- mean(abs(Roter_PhenoFlex_predictions$Error))

result <- data.frame(RMSEP = RMSEP, Mean = mean, `Absolute Mean` = abs_mean, check.names = FALSE)


kable(result) %>%
    kable_styling("striped", position = "left", font_size = 10)
```



------------------------------------------------------------------------

# Chapter 31: The PhenoFlex model - a second look

## ***Exercises on basic PhenoFlex diagnostics***

1. Make chill and heat response plots for the ‘Roter Boskoop’ PhenoFlex model for the location you did the earlier analyses for.


```{r}

library(tidyverse)
library(chillR)

Roter_par <-
  read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/PhenoFlex_parameters_Roter_Boskoop.csv")[,2]

E0 <- Roter_par[5]
E1 <- Roter_par[6]
A0 <- Roter_par[7]
A1 <- Roter_par[8]
Tf <- Roter_par[9]
slope <- Roter_par[12]

apply_const_temp <-
  function(temp, 
           A0, A1, E0, E1, Tf, 
           slope, portions = 1200, deg_celsius = TRUE) {
    temp_vector <- rep(temp,
                       times = portions)
    res <- chillR::DynModel_driver(temp = temp_vector,
                                   A0 = A0,
                                   A1 = A1,
                                   E0 = E0,
                                   E1 = E1,
                                   Tf = Tf,
                                   slope = slope,
                                   deg_celsius = deg_celsius)
    return(res$y[length(res$y)])
  }

apply_const_temp(4, A0, A1, E0, E1, Tf, 
                 slope)

gen_bell <- function(par,
                     temp_values = seq(-5, 20, 0.1)) {
  E0 <- par[5]
  E1 <- par[6]
  A0 <- par[7]
  A1 <- par[8]
  Tf <- par[9]
  slope <- par[12]

  y <- c()
  for(i in seq_along(temp_values)) {
    y[i] <- apply_const_temp(temp = temp_values[i],
                             A0 = A0,
                             A1 = A1,
                             E0 = E0,
                             E1 = E1,
                             Tf = Tf,
                             slope = slope)
  }
  return(invisible(y))
}

temp_values = seq(-5, 30, 0.1)

bell <- gen_bell(Roter_par,
                 temp_values)

plot(bell)

GDH_response <- function(T, par) {
  Tb <- par[11]
  Tu <- par[4]
  Tc <- par[10]
  GDH_weight <- rep(0, length(T))
  GDH_weight[which(T >= Tb & T <= Tu)] <-
    1/2 * (1 + cos(pi + pi * (T[which(T >= Tb & T <= Tu)] - Tb)/(Tu - Tb)))
  GDH_weight[which(T > Tu & T <= Tc)] <-
    (1 + cos(pi/2 + pi/2 * (T[which(T >  Tu & T <= Tc)] -Tu)/(Tc - Tu)))
  return(GDH_weight)
}




temp_values = seq(-5, 30, 0.1)

temp_response <- 
  data.frame(Temperature = temp_values,
             Chill_response = gen_bell(Roter_par,
                                       temp_values),
             Heat_response = GDH_response(temp_values,
                                          Roter_par))

pivoted_response <- pivot_longer(temp_response, 
                                 c(Chill_response,
                                   Heat_response))

ggplot(pivoted_response,
       aes(x = Temperature,
           y = value)) +
  geom_line(linewidth = 2,
            aes(col = name)) +
  ylab("Temperature response (arbitrary units)") +
  xlab("Temperature (°C)") +
  facet_wrap(vars(name),
             scales = "free",
             labeller = 
               labeller(name = c(Chill_response = c("Chill response"),
                                     Heat_response = c("Heat response")))) +
  scale_color_manual(values = c("Chill_response" = "blue",
                                "Heat_response" = "red")) +
  theme_bw(base_size = 15) +
  theme(legend.position = "none")


# Using Rochester as location
latitude <- 43.1

month_range <- c(10, 11, 12, 1, 2, 3)

Tmins = c(-20:20)
Tmaxs = c(-15:30)

mins <- NA
maxs <- NA
chill_eff <- NA
heat_eff <- NA
month <- NA

Roter_par <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/PhenoFlex_parameters_Roter_Boskoop.csv")[, 2]

simulation_par <- Roter_par

for (mon in month_range) {
    days_month <- as.numeric(difftime(ISOdate(2002, mon + 1, 1), ISOdate(2002, mon,
        1)))
    if (mon == 12)
        days_month <- 31
    weather <- make_all_day_table(data.frame(Year = c(2002, 2002), Month = c(mon,
        mon), Day = c(1, days_month), Tmin = c(0, 0), Tmax = c(0, 0)))

    for (tmin in Tmins) for (tmax in Tmaxs) if (tmax >= tmin) {
        hourtemps <- weather %>%
            mutate(Tmin = tmin, Tmax = tmax) %>%
            stack_hourly_temps(latitude = latitude) %>%
            pluck("hourtemps", "Temp")

        chill_eff <- c(chill_eff, PhenoFlex(temp = hourtemps, times = c(1:length(hourtemps)),
            A0 = simulation_par[7], A1 = simulation_par[8], E0 = simulation_par[5],
            E1 = simulation_par[6], Tf = simulation_par[9], slope = simulation_par[12],
            deg_celsius = TRUE, basic_output = FALSE)$y[length(hourtemps)]/(length(hourtemps)/24))

        heat_eff <- c(heat_eff, cumsum(GDH_response(hourtemps, simulation_par))[length(hourtemps)]/(length(hourtemps)/24))
        mins <- c(mins, tmin)
        maxs <- c(maxs, tmax)
        month <- c(month, mon)
    }
}

results <- data.frame(Month = month, Tmin = mins, Tmax = maxs, Chill_eff = chill_eff,
    Heat_eff = heat_eff) %>%
    filter(!is.na(Month))

write.csv(results, "C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/model_sensitivity_PhenoFlex_Roter.csv")

# Chill response plot
Model_sensitivities_PhenoFlex <- read.csv("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/model_sensitivity_PhenoFlex_Roter.csv")

Rochester_weather <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Rochester_weather.csv")


Chill_sensitivity_temps(Model_sensitivities_PhenoFlex, Rochester_weather, temp_model = "Chill_eff",
    month_range = c(10, 11, 12, 1, 2, 3), Tmins = c(-20:20), Tmaxs = c(-15:30), legend_label = "Chill per day \n(arbitrary)") +
    ggtitle("PhenoFlex chill efficiency ('Roter Boskoop')")
```

```{r}
# Heat response plot
Chill_sensitivity_temps(Model_sensitivities_PhenoFlex, Rochester_weather, temp_model = "Heat_eff",
    month_range = c(10, 11, 12, 1, 2, 3), Tmins = c(-20:20), Tmaxs = c(-15:30), legend_label = "Heat per day \n(arbitrary)") +
    ggtitle("PhenoFlex heat efficiency ('Roter Boskoop')")
```




------------------------------------------------------------------------

# Chapter 32: Can we improve the performance of PhenoFlex

## ***Exercises on improving the performance of PhenoFlex***

Describe (briefly) in your own words:

1. What was the objective of this work? 
The objective is to validate the  PhenoFlex model under different conditions. Also, some results obtained in the original publication suggest temperature responses during chill accumulation that seem implausible.

2. What was the main conclusion? 
Discussions on the major potential limitations of the PhenoFlex and other models. It has been obbserved that under extreme conditions, the process of dormancy breaking is modulated by mechanisms that are not considered in the PhenoFlex framework.

3. What experiments could we conduct to test the hypothesis that emerged at the end of the conclusion?
It has been concluded that additional systematic studies would have to be conducted.

------------------------------------------------------------------------

# Chapter 33: Frost risk analysis

## ***Exercises on frost risk analysis***

1.Download the phenology dataset for the apple cultivar Roter Boskoop from Klein-Altendorf.



```{r}
library(chillR)
library(tidyverse)
library(kableExtra)

CKA_Roter_Boskoop <- read_tab("C:/Users/Home/Documents/R Files/Trial Bookdown/data_New_York/Roter_Boskoop_bloom_1958_2019.csv.csv")


Roter_Boskoop <- CKA_Roter_Boskoop %>%
  pivot_longer(cols = "First_bloom":"Last_bloom",
               names_to = "variable",
               values_to="YEARMODA") %>%
  mutate(Year = as.numeric(substr(YEARMODA, 1, 4)),
         Month = as.numeric(substr(YEARMODA, 5, 6)),
         Day = as.numeric(substr(YEARMODA, 7, 8))) %>%
  make_JDay() 
```



2.Illustrate the development of the bloom period over the duration of the weather record. Use multiple ways to show this - feel free to be creative.



```{r}
# Illustrating with a scatter plot
library(chillR)
library(tidyverse)
library(kableExtra)

ggplot(data = Roter_Boskoop,aes(Pheno_year, JDay, col = variable)) +
  geom_point() + 
  geom_smooth(method=lm) +
  theme_bw(base_size=12) +
  scale_color_discrete(
    name = "Phenological event",
    labels = c("First bloom", "Full bloom", "Last bloom")) +
  xlab("Phenological year") +
  ylab("Julian date (day of the year)")
```



3. Evaluate the occurrence of frost events at Klein-Altendorf since 1958. Illustrate this in a plot.


```{r}
library(chillR)
library(tidyverse)
library(kableExtra)

# Generating model for frost hours (temperatures < 0°C)
frost_df = data.frame(
  lower = c(-1000, 0),
  upper = c(0, 1000),
  weight = c(1, 0))

frost_model <- function(x) step_model(x,
                                      frost_df)

# Convert temperature record to hourly values
hourly <- stack_hourly_temps(CKA_weather,
                             latitude = 50.625)

frost <- tempResponse(hourly,
                      models = c(frost = frost_model))

# Plot number of frost hours
ggplot(frost,
       aes(End_year,
           frost)) +
  geom_smooth() +
  geom_point() +
  ylim(c(0, NA)) +
  ylab("Frost hours per year") +
  xlab("Year")
```


 
4. Produce an illustration of the relationship between spring frost events and the bloom period of ‘Roter Boskoop’.



```{r}
# library(chillR)
# library(leaflet)
# library(tidyverse)
# library(kableExtra)
# library(Kendall)
# 
# # Generating model for frost hours (temperatures < 0°C)
# frost_df = data.frame(
#   lower = c(-1000, 0),
#   upper = c(0, 1000),
#   weight = c(1, 0))
# 
# frost_model <- function(x) step_model(x,
#                                       frost_df)
# 
# # Convert temperature record to hourly values
# hourly <- stack_hourly_temps(CKA_weather,
#                              latitude = 50.625)
# 
# frost <- tempResponse(hourly,
#                       models = c(frost = frost_model))
# 
# 
# # Ribbon for total bloom duration
# Ribbon_Boskoop <-
#   Roter_Boskoop %>%
#   select(Pheno_year, variable, JDay) %>%
#   pivot_wider(names_from = "variable", values_from = "JDay")
# 
# # Identify frost events that overlap with bloom 
# lookup_dates <- Ribbon_Boskoop
# 
# row.names(lookup_dates) <- lookup_dates$Pheno_year
# 
# Daily_frost[, "First_bloom"]<-
#   lookup_dates[as.character(Daily_frost$Year),
#                "First_bloom"]
# 
# Daily_frost[, "Last_bloom"] <-
#   lookup_dates[as.character(Daily_frost$Year),
#                "Last_bloom"]
# 
# Daily_frost[which(!is.na(Daily_frost$Frost_hours)),
#             "Bloom_frost"] <-
#   "Before bloom"
# 
# Daily_frost[which(Daily_frost$JDay >= Daily_frost$First_bloom),
#             "Bloom_frost"] <-
#   "During bloom"
# 
# Daily_frost[which(Daily_frost$JDay > Daily_frost$Last_bloom),
#             "Bloom_frost"] <-
#   "After bloom"
# 
# Daily_frost[which(Daily_frost$JDay > 180),
#             "Bloom_frost"] <-
#   "Before bloom"
# # Plot spring frost events that coincided with bloom
# ggplot(data = Ribbon_Boskoop,
#        aes(Pheno_year)) +
#   geom_ribbon(aes(ymin = First_bloom, 
#                   ymax = Last_bloom),
#               fill = "light gray") +
#   geom_line(aes(y = Full_bloom)) +
#   theme_bw(base_size = 15) +
#   xlab("Phenological year") +
#   ylab("Julian date (day of the year)") +
#   geom_point(data = Daily_frost,
#              aes(Year,
#                  JDay,
#                  size = Frost_hours,
#                  col = Bloom_frost),
#              alpha = 0.8) + 
#   scale_size(range = c(0, 5),
#              breaks = c(1, 5, 10, 15, 20),
#              labels = c("1", "5", "10", "15", "20"),
#              name = "Frost hours") +
#   scale_color_manual(
#     breaks = c("Before bloom",
#                "During bloom",
#                "After bloom"),
#     values = c("light green",
#                "red",
#                "light blue"),
#     name = "Frost timing") +
#   theme_bw(base_size = 15) +
#   ylim(c(75, 140))
```




5. Evaluate how the risk of spring frost for this cultivar has changed over time. Has there been a significant trend?



```{r}

# library(chillR)
# library(leaflet)
# library(tidyverse)
# library(kableExtra)
# library(Kendall)
# 
# # Generating model for frost hours (temperatures < 0°C)
# frost_df = data.frame(
#   lower = c(-1000, 0),
#   upper = c(0, 1000),
#   weight = c(1, 0))
# 
# frost_model <- function(x) step_model(x,
#                                       frost_df)
# 
# # Convert temperature record to hourly values
# hourly <- stack_hourly_temps(CKA_weather,
#                              latitude = 50.625)
# 
# frost <- tempResponse(hourly,
#                       models = c(frost = frost_model))
# 
# 
# # Investigate if there is a long-term trend in the number of frost hours during bloom
# Bloom_frost_trend <- 
#   aggregate(
#     Daily_frost$Frost_hours,
#     by = list(Daily_frost$Year,
#               Daily_frost$Bloom_frost),
#     FUN = function(x) sum(x,
#                           na.rm = TRUE))
# 
# colnames(Bloom_frost_trend) <- c("Year",
#                                  "Frost_timing",
#                                  "Frost_hours")
# 
# DuringBloom <-
#   Bloom_frost_trend[
#     which(Bloom_frost_trend$Frost_timing == "During bloom"),]
# 
# ggplot(data = DuringBloom,
#        aes(Year,
#            Frost_hours)) +
#   geom_col() +
#   ylab("Frost hours")
```

